{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mhbokaei/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torchnet as tnt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import os\n",
        "import json\n",
        "import pickle as pkl\n",
        "import argparse\n",
        "import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.12.1+cu116'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vUEHAOQlsCLH"
      },
      "outputs": [],
      "source": [
        "from models.stclassifier import PseTae\n",
        "from dataset import PixelSetData, PixelSetData_preloaded\n",
        "from learning.focal_loss import FocalLoss\n",
        "from learning.weight_init import weight_init\n",
        "from learning.metrics import mIou, confusion_matrix_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0a05UEVqsCNm"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_epoch(model, optimizer, criterion, data_loader, device, args):\n",
        "    acc_meter = tnt.meter.ClassErrorMeter(accuracy=True)\n",
        "    loss_meter = tnt.meter.AverageValueMeter()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for i, (x, y) in enumerate(data_loader):\n",
        "\n",
        "        y_true.extend(list(map(int, y)))\n",
        "\n",
        "        x = recursive_todevice(x, device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = out.detach()\n",
        "        y_p = pred.argmax(dim=1).cpu().numpy()\n",
        "        y_pred.extend(list(y_p))\n",
        "        acc_meter.add(pred, y)\n",
        "        loss_meter.add(loss.item())\n",
        "\n",
        "        if (i + 1) % args['display_step'] == 0:\n",
        "            print('Step [{}/{}], Loss: {:.4f}, Acc : {:.2f}'.format(i + 1, len(data_loader), loss_meter.value()[0],\n",
        "                                                                    acc_meter.value()[0]))\n",
        "\n",
        "    epoch_metrics = {'train_loss': loss_meter.value()[0],\n",
        "                     'train_accuracy': acc_meter.value()[0],\n",
        "                     'train_IoU': mIou(y_true, y_pred, n_classes=args['num_classes'])}\n",
        "\n",
        "    return epoch_metrics\n",
        "\n",
        "\n",
        "def evaluation(model, criterion, loader, device, args, mode='val'):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    acc_meter = tnt.meter.ClassErrorMeter(accuracy=True)\n",
        "    loss_meter = tnt.meter.AverageValueMeter()\n",
        "\n",
        "    for (x, y) in loader:\n",
        "        y_true.extend(list(map(int, y)))\n",
        "        x = recursive_todevice(x, device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prediction = model(x)\n",
        "            loss = criterion(prediction, y)\n",
        "\n",
        "        acc_meter.add(prediction, y)\n",
        "        loss_meter.add(loss.item())\n",
        "\n",
        "        y_p = prediction.argmax(dim=1).cpu().numpy()\n",
        "        y_pred.extend(list(y_p))\n",
        "\n",
        "    metrics = {'{}_accuracy'.format(mode): acc_meter.value()[0],\n",
        "               '{}_loss'.format(mode): loss_meter.value()[0],\n",
        "               '{}_IoU'.format(mode): mIou(y_true, y_pred, args['num_classes'])}\n",
        "\n",
        "    if mode == 'val':\n",
        "        return metrics\n",
        "    elif mode == 'test':\n",
        "        return metrics, confusion_matrix(y_true, y_pred, labels=list(range(args['num_classes'])))\n",
        "\n",
        "\n",
        "def get_loaders(dt, kfold, args):\n",
        "    indices = list(range(len(dt)))\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    kf = KFold(n_splits=kfold, shuffle=False)\n",
        "    indices_seq = list(kf.split(list(range(len(dt)))))\n",
        "    ntest = len(indices_seq[0][1])\n",
        "\n",
        "    loader_seq = []\n",
        "    for trainval, test_indices in indices_seq:\n",
        "        trainval = [indices[i] for i in trainval]\n",
        "        test_indices = [indices[i] for i in test_indices]\n",
        "\n",
        "        validation_indices = trainval[-ntest:]\n",
        "        train_indices = trainval[:-ntest]\n",
        "\n",
        "        train_sampler = data.sampler.SubsetRandomSampler(train_indices)\n",
        "        validation_sampler = data.sampler.SubsetRandomSampler(validation_indices)\n",
        "        test_sampler = data.sampler.SubsetRandomSampler(test_indices)\n",
        "\n",
        "        train_loader = data.DataLoader(dt, batch_size=args['batch_size'],\n",
        "                                       sampler=train_sampler,\n",
        "                                       num_workers=args['num_workers'])\n",
        "        validation_loader = data.DataLoader(dt, batch_size=args['batch_size'],\n",
        "                                            sampler=validation_sampler,\n",
        "                                            num_workers=args['num_workers'])\n",
        "        test_loader = data.DataLoader(dt, batch_size=args['batch_size'],\n",
        "                                      sampler=test_sampler,\n",
        "                                      num_workers=args['num_workers'])\n",
        "\n",
        "        loader_seq.append((train_loader, validation_loader, test_loader))\n",
        "    return loader_seq\n",
        "\n",
        "\n",
        "def get_loaders_sepT(dt,dt_sepT, kfold, args):\n",
        "    indices = list(range(len(dt)))\n",
        "    indices_T = list(range(len(dt_sepT)))\n",
        "    np.random.shuffle(indices)\n",
        "    np.random.shuffle(indices_T)\n",
        "\n",
        "\n",
        "    kf = KFold(n_splits=kfold, shuffle=False)\n",
        "    indices_seq = list(kf.split(list(range(len(dt)))))\n",
        "    indices_seq_T = list(range(len(dt_sepT)))\n",
        "\n",
        "    def add_element(main_matrix, \n",
        "                    temp_matrix = indices_seq_T):\n",
        "        main_matrix = list(main_matrix)\n",
        "        main_matrix.append(temp_matrix)\n",
        "        main_matrix = tuple(main_matrix)\n",
        "        return main_matrix\n",
        "\n",
        "    indices_seqq = tuple(map(add_element , indices_seq))\n",
        "\n",
        "    loader_seq = []\n",
        "    for train_indices, validation_indices, test_indices in indices_seqq:\n",
        "        train_indices = [indices[i] for i in train_indices]\n",
        "        validation_indices = [indices[i] for i in validation_indices]\n",
        "        test_indices = [indices_T[i] for i in test_indices]\n",
        "        \n",
        "        train_sampler = data.sampler.SubsetRandomSampler(train_indices)\n",
        "        validation_sampler = data.sampler.SubsetRandomSampler(validation_indices)\n",
        "        test_sampler = data.sampler.SubsetRandomSampler(test_indices)\n",
        "\n",
        "        train_loader = data.DataLoader(dt, batch_size=args['batch_size'],\n",
        "                                       sampler=train_sampler,\n",
        "                                       num_workers=args['num_workers'])\n",
        "        validation_loader = data.DataLoader(dt, batch_size=args['batch_size'],\n",
        "                                            sampler=validation_sampler,\n",
        "                                            num_workers=args['num_workers'])\n",
        "        test_loader = data.DataLoader(dt_sepT, batch_size=args['batch_size'],\n",
        "                                      sampler=test_sampler,\n",
        "                                      num_workers=args['num_workers'])\n",
        "\n",
        "        loader_seq.append((train_loader, validation_loader, test_loader))\n",
        "    return loader_seq\n",
        "\n",
        "def recursive_todevice(x, device):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x.to(device)\n",
        "    else:\n",
        "        return [recursive_todevice(c, device) for c in x]\n",
        "\n",
        "\n",
        "def prepare_output(args):\n",
        "    os.makedirs(args['res_dir'], exist_ok=True)\n",
        "    for fold in range(1, args['kfold'] + 1):\n",
        "        os.makedirs(os.path.join(args['res_dir'], 'Fold_{}'.format(fold)), exist_ok=True)\n",
        "\n",
        "\n",
        "def checkpoint(fold, log, args):\n",
        "    with open(os.path.join(args['res_dir'], 'Fold_{}'.format(fold), 'trainlog.json'), 'w') as outfile:\n",
        "        json.dump(log, outfile, indent=4)\n",
        "\n",
        "\n",
        "def save_results(fold, metrics, conf_mat, args):\n",
        "    with open(os.path.join(args['res_dir'], 'Fold_{}'.format(fold), 'test_metrics.json'), 'w') as outfile:\n",
        "        json.dump(metrics, outfile, indent=4)\n",
        "    pkl.dump(conf_mat, open(os.path.join(args['res_dir'], 'Fold_{}'.format(fold), 'conf_mat.pkl'), 'wb'))\n",
        "\n",
        "\n",
        "def overall_performance(args):\n",
        "    cm = np.zeros((args['num_classes'], args['num_classes']))\n",
        "    for fold in range(1, args['kfold'] + 1):\n",
        "        cm += pkl.load(open(os.path.join(args['res_dir'], 'Fold_{}'.format(fold), 'conf_mat.pkl'), 'rb'))\n",
        "\n",
        "    _, perf = confusion_matrix_analysis(cm)\n",
        "\n",
        "    print('Overall performance:')\n",
        "    print('Acc: {},  IoU: {}'.format(perf['Accuracy'], perf['MACRO_IoU']))\n",
        "\n",
        "    with open(os.path.join(args['res_dir'], 'overall.json'), 'w') as file:\n",
        "        file.write(json.dumps(perf, indent=4))\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    np.random.seed(args['rdm_seed'])\n",
        "    torch.manual_seed(args['rdm_seed'])\n",
        "    prepare_output(args)\n",
        "    mean_std = pkl.load(open(args['dataset_folder'] + '/S2-2017-T31TFM-meanstd.pkl', 'rb'))\n",
        "    mean_std_sepT = pkl.load(open(args['dataset_folder_sepT'] + '/S2-2017-T31TFM-meanstd.pkl', 'rb'))\n",
        "\n",
        "    # 19 - 44 classes None\n",
        "\n",
        "    extra = 'geomfeat' if args['geomfeat'] else None\n",
        "\n",
        "    if args['preload']:\n",
        "        dt = PixelSetData_preloaded(args['dataset_folder'], labels='label_19class', npixel=args['npixel'],\n",
        "                          sub_classes= None,\n",
        "                          norm=mean_std,\n",
        "                          extra_feature=extra)\n",
        "        dt_sepT = PixelSetData_preloaded(args['dataset_folder_sepT'], labels='label_19class', npixel=args['npixel'],\n",
        "                          sub_classes= None,\n",
        "                          norm=mean_std_sepT,\n",
        "                          extra_feature=extra)        \n",
        "    else:\n",
        "        dt = PixelSetData(args['dataset_folder'], labels='label_19class', npixel=args['npixel'],\n",
        "                          sub_classes= None,\n",
        "                          norm=mean_std,\n",
        "                          extra_feature=extra)\n",
        "        dt_sepT = PixelSetData(args['dataset_folder_sepT'], labels='label_19class', npixel=args['npixel'],\n",
        "                          sub_classes= None,\n",
        "                          norm=mean_std_sepT,\n",
        "                          extra_feature=extra)        \n",
        "        \n",
        "    device = torch.device(args['device'])\n",
        "    print(\"len(dt)1: \",len(dt))\n",
        "\n",
        "    if args['separate_test'] == 'yes' :\n",
        "        loaders = get_loaders_sepT(dt, dt_sepT, args['kfold'], args)\n",
        "    elif args['separate_test'] == 'no':\n",
        "        loaders = get_loaders(dt, args['kfold'], args)\n",
        "\n",
        "    for fold, (train_loader, val_loader, test_loader) in enumerate(loaders):\n",
        "        print(\"len(dt)0: \",len(dt))\n",
        "        print(\"len(dt_sepT)0: \",len(dt_sepT))\n",
        "        print('Starting Fold {}'.format(fold + 1))\n",
        "        print('Train {}, Val {}, Test {}'.format(len(train_loader), len(val_loader), len(test_loader)))\n",
        "        print(\"test_loader: \", test_loader)\n",
        "\n",
        "        model_args= dict(input_dim=args['input_dim'], mlp1=args['mlp1'], pooling=args['pooling'],\n",
        "                            mlp2=args['mlp2'], n_head=args['n_head'], d_k=args['d_k'], mlp3=args['mlp3'],\n",
        "                            dropout=args['dropout'], T=args['T'], len_max_seq=args['lms'],\n",
        "                            positions=dt.date_positions if args['positions'] == 'bespoke' else None,\n",
        "                            mlp4=args['mlp4'])\n",
        "\n",
        "        if args['geomfeat']:\n",
        "            model_args.update(with_extra=True, extra_size=4)\n",
        "        else:\n",
        "            model_args.update(with_extra=False, extra_size=None)\n",
        "\n",
        "        model = PseTae(**model_args)\n",
        "\n",
        "        print(model.param_ratio())\n",
        "\n",
        "        model = model.to(device)\n",
        "        model.apply(weight_init)\n",
        "        optimizer = torch.optim.Adam(model.parameters())\n",
        "        criterion = FocalLoss(args['gamma'])\n",
        "\n",
        "        trainlog = {}\n",
        "\n",
        "\n",
        "\n",
        "        best_mIoU = 0\n",
        "        for epoch in range(1, args['epochs'] + 1):\n",
        "            print('EPOCH {}/{}'.format(epoch, args['epochs']))\n",
        "\n",
        "            model.train()\n",
        "            train_metrics = train_epoch(model, optimizer, criterion, train_loader, device=device, args=args)\n",
        "\n",
        "            print('Validation . . . ')\n",
        "            model.eval()\n",
        "            val_metrics = evaluation(model, criterion, val_loader, device=device, args=args, mode='val')\n",
        "\n",
        "            print('Loss {:.4f},  Acc {:.2f},  IoU {:.4f}'.format(val_metrics['val_loss'], val_metrics['val_accuracy'],\n",
        "                                                                 val_metrics['val_IoU']))\n",
        "\n",
        "            trainlog[epoch] = {**train_metrics, **val_metrics}\n",
        "            checkpoint(fold + 1, trainlog, args)\n",
        "\n",
        "            if val_metrics['val_IoU'] >= best_mIoU:\n",
        "                best_mIoU = val_metrics['val_IoU']\n",
        "                torch.save({'epoch': epoch, 'state_dict': model.state_dict(),\n",
        "                            'optimizer': optimizer.state_dict()},\n",
        "                           os.path.join(args['res_dir'], 'Fold_{}'.format(fold + 1), 'model.pth.tar'))\n",
        "\n",
        "        print('Testing best epoch . . .')\n",
        "        model.load_state_dict(\n",
        "            torch.load(os.path.join(args['res_dir'], 'Fold_{}'.format(fold + 1), 'model.pth.tar'))['state_dict'])\n",
        "        model.eval()\n",
        "\n",
        "        test_metrics, conf_mat = evaluation(model, criterion, test_loader, device=device, mode='test', args=args)\n",
        "\n",
        "        print('Loss {:.4f},  Acc {:.2f},  IoU {:.4f}'.format(test_metrics['test_loss'], test_metrics['test_accuracy'],\n",
        "                                                             test_metrics['test_IoU']))\n",
        "        save_results(fold + 1, test_metrics, conf_mat, args)\n",
        "\n",
        "    overall_performance(args)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aT1XanDusCP2",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # Set-up parameters\n",
        "    # /home/mhbokaei/shakouri/test/Satellite/dataset_folder100\n",
        "    # /home/mhbokaei/shakouri/test/Satellite/dataset_folder10000\n",
        "    # /home/mhbokaei/shakouri/test/Satellite/dataset_folder90000\n",
        "    # /home/mhbokaei/shakouri/SatelliteImage_TimeSeries_Classification/dataset_folder\n",
        "    \n",
        "    \n",
        "    parser.add_argument('--dataset_folder', default='/home/mhbokaei/shakouri/test/Satellite/dataset_folder10000', type=str,\n",
        "                        help='Path to the folder where the results are saved.')\n",
        "    parser.add_argument('--dataset_folder_sepT', default='/home/mhbokaei/shakouri/test/Satellite/dataset_folder100', type=str,\n",
        "                        help='Path to the folder where the results are saved.')\n",
        "    parser.add_argument('--separate_test', default='yes', type=str, help='Shows the dataset for Test is different')\n",
        "\n",
        "    parser.add_argument('--res_dir', default='./results', help='Path to the folder where the results should be stored')\n",
        "    parser.add_argument('--num_workers', default=8, type=int, help='Number of data loading workers')\n",
        "    parser.add_argument('--rdm_seed', default=1, type=int, help='Random seed')\n",
        "    parser.add_argument('--device', default='cuda', type=str,\n",
        "                        help='Name of device to use for tensor computations (cuda/cpu)')\n",
        "    parser.add_argument('--display_step', default=20, type=int,\n",
        "                        help='Interval in batches between display of training metrics')\n",
        "    parser.add_argument('--preload', dest='preload', action='store_true',\n",
        "                        help='If specified, the whole dataset is loaded to RAM at initialization')\n",
        "    parser.set_defaults(preload=False)\n",
        "\n",
        "    # Training parameters\n",
        "    parser.add_argument('--kfold', default=5, type=int, help='Number of folds for cross validation')\n",
        "    parser.add_argument('--epochs', default=2, type=int, help='Number of epochs per fold')\n",
        "    parser.add_argument('--batch_size', default=20, type=int, help='Batch size')\n",
        "    parser.add_argument('--lr', default=0.001, type=float, help='Learning rate')\n",
        "    parser.add_argument('--gamma', default=1, type=float, help='Gamma parameter of the focal loss')\n",
        "    parser.add_argument('--npixel', default=3, type=int, help='Number of pixels to sample from the input images')\n",
        "\n",
        "    # Architecture Hyperparameters\n",
        "    ## PSE\n",
        "    parser.add_argument('--input_dim', default=10, type=int, help='Number of channels of input images')\n",
        "    parser.add_argument('--mlp1', default='[10,32,64]', type=str, help='Number of neurons in the layers of MLP1')\n",
        "    parser.add_argument('--pooling', default='mean_std', type=str, help='Pixel-embeddings pooling strategy')\n",
        "    parser.add_argument('--mlp2', default='[132,128]', type=str, help='Number of neurons in the layers of MLP2')\n",
        "    parser.add_argument('--geomfeat', default=1, type=int,\n",
        "                        help='If 1 the precomputed geometrical features (f) are used in the PSE.')\n",
        "\n",
        "    ## TAE\n",
        "    parser.add_argument('--n_head', default=4, type=int, help='Number of attention heads')\n",
        "    parser.add_argument('--d_k', default=32, type=int, help='Dimension of the key and query vectors')\n",
        "    parser.add_argument('--mlp3', default='[512,128,128]', type=str, help='Number of neurons in the layers of MLP3')\n",
        "    parser.add_argument('--T', default=1000, type=int, help='Maximum period for the positional encoding')\n",
        "    parser.add_argument('--positions', default='bespoke', type=str,\n",
        "                        help='Positions to use for the positional encoding (bespoke / order)')\n",
        "    parser.add_argument('--lms', default=None, type=int,\n",
        "                        help='Maximum sequence length for positional encoding (only necessary if positions == order)')\n",
        "    parser.add_argument('--dropout', default=0.2, type=float, help='Dropout probability')\n",
        "\n",
        "    ## Classifier\n",
        "    parser.add_argument('--num_classes', default=19, type=int, help='Number of classes')\n",
        "    parser.add_argument('--mlp4', default='[128, 64, 32, 19]', type=str, help='Number of neurons in the layers of MLP4')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcR-4SkvsCSJ",
        "metadata": {},
        "outputId": "cb32d98d-f261-401a-8eb7-d483a6e12bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'T': 1000,\n",
            " 'batch_size': 20,\n",
            " 'd_k': 32,\n",
            " 'dataset_folder': '/home/mhbokaei/shakouri/test/Satellite/dataset_folder10000',\n",
            " 'dataset_folder_sepT': '/home/mhbokaei/shakouri/test/Satellite/dataset_folder100',\n",
            " 'device': 'cuda',\n",
            " 'display_step': 20,\n",
            " 'dropout': 0.2,\n",
            " 'epochs': 2,\n",
            " 'gamma': 1,\n",
            " 'geomfeat': 1,\n",
            " 'input_dim': 10,\n",
            " 'kfold': 5,\n",
            " 'lms': None,\n",
            " 'lr': 0.001,\n",
            " 'mlp1': [10, 32, 64],\n",
            " 'mlp2': [132, 128],\n",
            " 'mlp3': [512, 128, 128],\n",
            " 'mlp4': [128, 64, 32, 19],\n",
            " 'n_head': 4,\n",
            " 'npixel': 3,\n",
            " 'num_classes': 19,\n",
            " 'num_workers': 8,\n",
            " 'pooling': 'mean_std',\n",
            " 'positions': 'bespoke',\n",
            " 'preload': False,\n",
            " 'rdm_seed': 1,\n",
            " 'res_dir': './results',\n",
            " 'separate_test': 'yes'}\n",
            "len(dt)1:  9975\n",
            "len(dt)0:  9975\n",
            "len(dt_sepT)0:  98\n",
            "Starting Fold 1\n",
            "Train 399, Val 100, Test 5\n",
            "test_loader:  <torch.utils.data.dataloader.DataLoader object at 0x7f35c5b1b4f0>\n",
            "TOTAL TRAINABLE PARAMETERS : 164083\n",
            "RATIOS: Spatial  12.1% , Temporal  81.1% , Classifier   6.8%\n",
            "None\n",
            "EPOCH 1/2\n",
            "Step [20/399], Loss: 2.0004, Acc : 26.00\n",
            "Step [40/399], Loss: 1.6274, Acc : 44.00\n",
            "Step [60/399], Loss: 1.3648, Acc : 55.58\n",
            "Step [80/399], Loss: 1.1815, Acc : 63.06\n",
            "Step [100/399], Loss: 1.0628, Acc : 67.40\n",
            "Step [120/399], Loss: 0.9754, Acc : 70.46\n",
            "Step [140/399], Loss: 0.9050, Acc : 72.64\n",
            "Step [160/399], Loss: 0.8631, Acc : 73.69\n",
            "Step [180/399], Loss: 0.8207, Acc : 75.06\n",
            "Step [200/399], Loss: 0.7768, Acc : 76.28\n",
            "Step [220/399], Loss: 0.7453, Acc : 77.16\n",
            "Step [240/399], Loss: 0.7162, Acc : 77.88\n",
            "Step [260/399], Loss: 0.6916, Acc : 78.54\n",
            "Step [280/399], Loss: 0.6771, Acc : 78.79\n",
            "Step [300/399], Loss: 0.6516, Acc : 79.50\n",
            "Step [320/399], Loss: 0.6332, Acc : 79.84\n",
            "Step [340/399], Loss: 0.6226, Acc : 80.09\n",
            "Step [360/399], Loss: 0.6115, Acc : 80.38\n",
            "Step [380/399], Loss: 0.6003, Acc : 80.74\n",
            "Validation . . . \n",
            "Loss 0.3031,  Acc 90.38,  IoU 0.1647\n",
            "EPOCH 2/2\n",
            "Step [20/399], Loss: 0.3402, Acc : 87.00\n",
            "Step [40/399], Loss: 0.3088, Acc : 88.75\n",
            "Step [60/399], Loss: 0.3098, Acc : 89.25\n",
            "Step [80/399], Loss: 0.3145, Acc : 89.31\n",
            "Step [100/399], Loss: 0.3171, Acc : 88.65\n",
            "Step [120/399], Loss: 0.3041, Acc : 89.00\n",
            "Step [140/399], Loss: 0.3064, Acc : 89.00\n",
            "Step [160/399], Loss: 0.3025, Acc : 89.12\n",
            "Step [180/399], Loss: 0.2979, Acc : 89.11\n",
            "Step [200/399], Loss: 0.2989, Acc : 89.03\n",
            "Step [220/399], Loss: 0.2968, Acc : 89.07\n",
            "Step [240/399], Loss: 0.2938, Acc : 89.15\n",
            "Step [260/399], Loss: 0.2893, Acc : 89.10\n",
            "Step [280/399], Loss: 0.2922, Acc : 89.00\n",
            "Step [300/399], Loss: 0.2939, Acc : 88.88\n",
            "Step [320/399], Loss: 0.2943, Acc : 88.88\n",
            "Step [340/399], Loss: 0.2947, Acc : 88.76\n",
            "Step [360/399], Loss: 0.2936, Acc : 88.88\n",
            "Step [380/399], Loss: 0.2935, Acc : 88.96\n",
            "Validation . . . \n",
            "Loss 0.2494,  Acc 90.88,  IoU 0.2127\n",
            "Testing best epoch . . .\n",
            "Loss 0.1196,  Acc 94.90,  IoU 0.8692\n",
            "len(dt)0:  9975\n",
            "len(dt_sepT)0:  98\n",
            "Starting Fold 2\n",
            "Train 399, Val 100, Test 5\n",
            "test_loader:  <torch.utils.data.dataloader.DataLoader object at 0x7f35c5b1ba90>\n",
            "TOTAL TRAINABLE PARAMETERS : 164083\n",
            "RATIOS: Spatial  12.1% , Temporal  81.1% , Classifier   6.8%\n",
            "None\n",
            "EPOCH 1/2\n",
            "Step [20/399], Loss: 2.6400, Acc : 9.00\n",
            "Step [40/399], Loss: 2.2095, Acc : 26.50\n",
            "Step [60/399], Loss: 1.8640, Acc : 41.83\n",
            "Step [80/399], Loss: 1.6244, Acc : 50.81\n",
            "Step [100/399], Loss: 1.4313, Acc : 57.80\n",
            "Step [120/399], Loss: 1.3047, Acc : 61.75\n",
            "Step [140/399], Loss: 1.1935, Acc : 65.32\n",
            "Step [160/399], Loss: 1.1026, Acc : 68.06\n",
            "Step [180/399], Loss: 1.0373, Acc : 69.94\n",
            "Step [200/399], Loss: 0.9746, Acc : 71.62\n",
            "Step [220/399], Loss: 0.9278, Acc : 72.80\n",
            "Step [240/399], Loss: 0.8776, Acc : 74.17\n",
            "Step [260/399], Loss: 0.8388, Acc : 75.27\n",
            "Step [280/399], Loss: 0.8056, Acc : 76.21\n",
            "Step [300/399], Loss: 0.7820, Acc : 76.88\n",
            "Step [320/399], Loss: 0.7582, Acc : 77.50\n",
            "Step [340/399], Loss: 0.7361, Acc : 78.01\n",
            "Step [360/399], Loss: 0.7142, Acc : 78.64\n",
            "Step [380/399], Loss: 0.6967, Acc : 79.00\n",
            "Validation . . . \n",
            "Loss 0.2628,  Acc 91.08,  IoU 0.2073\n",
            "EPOCH 2/2\n",
            "Step [20/399], Loss: 0.3186, Acc : 89.00\n",
            "Step [40/399], Loss: 0.3193, Acc : 89.12\n",
            "Step [60/399], Loss: 0.3340, Acc : 89.00\n",
            "Step [80/399], Loss: 0.3387, Acc : 88.12\n",
            "Step [100/399], Loss: 0.3343, Acc : 88.00\n",
            "Step [120/399], Loss: 0.3407, Acc : 87.83\n",
            "Step [140/399], Loss: 0.3381, Acc : 87.96\n",
            "Step [160/399], Loss: 0.3255, Acc : 88.28\n",
            "Step [180/399], Loss: 0.3189, Acc : 88.56\n",
            "Step [200/399], Loss: 0.3118, Acc : 88.88\n",
            "Step [220/399], Loss: 0.3095, Acc : 88.93\n",
            "Step [240/399], Loss: 0.3121, Acc : 88.77\n",
            "Step [260/399], Loss: 0.3090, Acc : 88.81\n",
            "Step [280/399], Loss: 0.3058, Acc : 88.84\n",
            "Step [300/399], Loss: 0.3032, Acc : 88.93\n",
            "Step [320/399], Loss: 0.3016, Acc : 88.94\n",
            "Step [340/399], Loss: 0.3043, Acc : 88.93\n",
            "Step [360/399], Loss: 0.3054, Acc : 88.83\n",
            "Step [380/399], Loss: 0.3068, Acc : 88.70\n",
            "Validation . . . \n",
            "Loss 0.2093,  Acc 91.73,  IoU 0.2606\n",
            "Testing best epoch . . .\n",
            "Loss 0.0940,  Acc 97.96,  IoU 0.9120\n",
            "len(dt)0:  9975\n",
            "len(dt_sepT)0:  98\n",
            "Starting Fold 3\n",
            "Train 399, Val 100, Test 5\n",
            "test_loader:  <torch.utils.data.dataloader.DataLoader object at 0x7f35c265b8e0>\n",
            "TOTAL TRAINABLE PARAMETERS : 164083\n",
            "RATIOS: Spatial  12.1% , Temporal  81.1% , Classifier   6.8%\n",
            "None\n",
            "EPOCH 1/2\n",
            "Step [20/399], Loss: 2.8553, Acc : 13.00\n",
            "Step [40/399], Loss: 2.3616, Acc : 31.75\n",
            "Step [60/399], Loss: 2.0374, Acc : 43.83\n",
            "Step [80/399], Loss: 1.7848, Acc : 52.56\n",
            "Step [100/399], Loss: 1.5931, Acc : 58.75\n",
            "Step [120/399], Loss: 1.4462, Acc : 63.04\n",
            "Step [140/399], Loss: 1.3402, Acc : 65.96\n",
            "Step [160/399], Loss: 1.2372, Acc : 68.56\n",
            "Step [180/399], Loss: 1.1490, Acc : 70.75\n",
            "Step [200/399], Loss: 1.0738, Acc : 72.52\n",
            "Step [220/399], Loss: 1.0288, Acc : 73.48\n",
            "Step [240/399], Loss: 0.9791, Acc : 74.60\n",
            "Step [260/399], Loss: 0.9342, Acc : 75.58\n",
            "Step [280/399], Loss: 0.8945, Acc : 76.50\n",
            "Step [300/399], Loss: 0.8590, Acc : 77.27\n",
            "Step [320/399], Loss: 0.8311, Acc : 77.83\n",
            "Step [340/399], Loss: 0.8041, Acc : 78.40\n",
            "Step [360/399], Loss: 0.7823, Acc : 78.76\n",
            "Step [380/399], Loss: 0.7607, Acc : 79.18\n",
            "Validation . . . \n",
            "Loss 0.2711,  Acc 90.58,  IoU 0.1676\n",
            "EPOCH 2/2\n",
            "Step [20/399], Loss: 0.2624, Acc : 91.25\n",
            "Step [40/399], Loss: 0.2755, Acc : 90.88\n",
            "Step [60/399], Loss: 0.3154, Acc : 89.17\n",
            "Step [80/399], Loss: 0.3211, Acc : 88.88\n",
            "Step [100/399], Loss: 0.3299, Acc : 88.45\n",
            "Step [120/399], Loss: 0.3188, Acc : 88.83\n",
            "Step [140/399], Loss: 0.3173, Acc : 89.00\n",
            "Step [160/399], Loss: 0.3200, Acc : 88.78\n",
            "Step [180/399], Loss: 0.3127, Acc : 89.11\n",
            "Step [200/399], Loss: 0.3097, Acc : 89.18\n",
            "Step [220/399], Loss: 0.3094, Acc : 89.16\n",
            "Step [240/399], Loss: 0.3107, Acc : 89.12\n",
            "Step [260/399], Loss: 0.3074, Acc : 89.23\n",
            "Step [280/399], Loss: 0.3110, Acc : 89.12\n",
            "Step [300/399], Loss: 0.3116, Acc : 89.07\n",
            "Step [320/399], Loss: 0.3138, Acc : 89.09\n",
            "Step [340/399], Loss: 0.3140, Acc : 89.15\n",
            "Step [360/399], Loss: 0.3101, Acc : 89.21\n",
            "Step [380/399], Loss: 0.3093, Acc : 89.16\n",
            "Validation . . . \n",
            "Loss 0.2016,  Acc 92.18,  IoU 0.2093\n",
            "Testing best epoch . . .\n",
            "Loss 0.1192,  Acc 92.86,  IoU 0.8127\n",
            "len(dt)0:  9975\n",
            "len(dt_sepT)0:  98\n",
            "Starting Fold 4\n",
            "Train 399, Val 100, Test 5\n",
            "test_loader:  <torch.utils.data.dataloader.DataLoader object at 0x7f35ccaaccd0>\n",
            "TOTAL TRAINABLE PARAMETERS : 164083\n",
            "RATIOS: Spatial  12.1% , Temporal  81.1% , Classifier   6.8%\n",
            "None\n",
            "EPOCH 1/2\n",
            "Step [20/399], Loss: 3.8527, Acc : 0.50\n",
            "Step [40/399], Loss: 3.4555, Acc : 0.88\n",
            "Step [60/399], Loss: 3.1334, Acc : 1.42\n",
            "Step [80/399], Loss: 2.8390, Acc : 4.81\n",
            "Step [100/399], Loss: 2.5618, Acc : 10.05\n",
            "Step [120/399], Loss: 2.3415, Acc : 17.87\n",
            "Step [140/399], Loss: 2.1343, Acc : 26.57\n",
            "Step [160/399], Loss: 1.9602, Acc : 33.63\n",
            "Step [180/399], Loss: 1.8005, Acc : 39.72\n",
            "Step [200/399], Loss: 1.6668, Acc : 44.60\n",
            "Step [220/399], Loss: 1.5590, Acc : 48.55\n",
            "Step [240/399], Loss: 1.4681, Acc : 51.75\n",
            "Step [260/399], Loss: 1.3877, Acc : 54.48\n",
            "Step [280/399], Loss: 1.3167, Acc : 56.80\n",
            "Step [300/399], Loss: 1.2587, Acc : 58.80\n",
            "Step [320/399], Loss: 1.2028, Acc : 60.62\n",
            "Step [340/399], Loss: 1.1518, Acc : 62.31\n",
            "Step [360/399], Loss: 1.1137, Acc : 63.47\n",
            "Step [380/399], Loss: 1.0750, Acc : 64.70\n",
            "Validation . . . \n",
            "Loss 0.2773,  Acc 91.33,  IoU 0.1796\n",
            "EPOCH 2/2\n",
            "Step [20/399], Loss: 0.3140, Acc : 89.00\n",
            "Step [40/399], Loss: 0.3184, Acc : 89.12\n",
            "Step [60/399], Loss: 0.3241, Acc : 89.00\n",
            "Step [80/399], Loss: 0.3166, Acc : 89.19\n",
            "Step [100/399], Loss: 0.3073, Acc : 89.55\n",
            "Step [120/399], Loss: 0.3055, Acc : 89.29\n",
            "Step [140/399], Loss: 0.2956, Acc : 89.43\n",
            "Step [160/399], Loss: 0.2951, Acc : 89.50\n",
            "Step [180/399], Loss: 0.2969, Acc : 89.33\n",
            "Step [200/399], Loss: 0.3035, Acc : 89.08\n",
            "Step [220/399], Loss: 0.3032, Acc : 88.86\n",
            "Step [240/399], Loss: 0.3060, Acc : 88.67\n",
            "Step [260/399], Loss: 0.3062, Acc : 88.62\n",
            "Step [280/399], Loss: 0.3078, Acc : 88.64\n",
            "Step [300/399], Loss: 0.3132, Acc : 88.47\n",
            "Step [320/399], Loss: 0.3115, Acc : 88.31\n",
            "Step [340/399], Loss: 0.3087, Acc : 88.41\n",
            "Step [360/399], Loss: 0.3073, Acc : 88.46\n",
            "Step [380/399], Loss: 0.3061, Acc : 88.53\n",
            "Validation . . . \n",
            "Loss 0.2293,  Acc 92.08,  IoU 0.1848\n",
            "Testing best epoch . . .\n",
            "Loss 0.0994,  Acc 94.90,  IoU 0.8692\n",
            "len(dt)0:  9975\n",
            "len(dt_sepT)0:  98\n",
            "Starting Fold 5\n",
            "Train 399, Val 100, Test 5\n",
            "test_loader:  <torch.utils.data.dataloader.DataLoader object at 0x7f35ccaac8e0>\n",
            "TOTAL TRAINABLE PARAMETERS : 164083\n",
            "RATIOS: Spatial  12.1% , Temporal  81.1% , Classifier   6.8%\n",
            "None\n",
            "EPOCH 1/2\n",
            "Step [20/399], Loss: 3.5796, Acc : 0.75\n",
            "Step [40/399], Loss: 3.2002, Acc : 0.88\n",
            "Step [60/399], Loss: 2.8436, Acc : 3.58\n",
            "Step [80/399], Loss: 2.5443, Acc : 13.25\n",
            "Step [100/399], Loss: 2.2762, Acc : 24.65\n",
            "Step [120/399], Loss: 2.0529, Acc : 34.25\n",
            "Step [140/399], Loss: 1.8794, Acc : 41.21\n",
            "Step [160/399], Loss: 1.7204, Acc : 46.91\n",
            "Step [180/399], Loss: 1.5915, Acc : 51.17\n",
            "Step [200/399], Loss: 1.4764, Acc : 55.10\n",
            "Step [220/399], Loss: 1.3889, Acc : 57.95\n",
            "Step [240/399], Loss: 1.3072, Acc : 60.54\n",
            "Step [260/399], Loss: 1.2422, Acc : 62.62\n",
            "Step [280/399], Loss: 1.1811, Acc : 64.38\n",
            "Step [300/399], Loss: 1.1321, Acc : 65.97\n",
            "Step [320/399], Loss: 1.0891, Acc : 67.30\n",
            "Step [340/399], Loss: 1.0555, Acc : 68.18\n",
            "Step [360/399], Loss: 1.0193, Acc : 69.14\n",
            "Step [380/399], Loss: 0.9861, Acc : 70.11\n",
            "Validation . . . \n",
            "Loss 0.2514,  Acc 92.13,  IoU 0.1943\n",
            "EPOCH 2/2\n",
            "Step [20/399], Loss: 0.3175, Acc : 89.00\n",
            "Step [40/399], Loss: 0.3446, Acc : 88.25\n",
            "Step [60/399], Loss: 0.3444, Acc : 88.00\n",
            "Step [80/399], Loss: 0.3411, Acc : 88.19\n",
            "Step [100/399], Loss: 0.3434, Acc : 88.05\n",
            "Step [120/399], Loss: 0.3318, Acc : 88.42\n",
            "Step [140/399], Loss: 0.3172, Acc : 88.93\n",
            "Step [160/399], Loss: 0.3184, Acc : 88.84\n",
            "Step [180/399], Loss: 0.3155, Acc : 88.94\n",
            "Step [200/399], Loss: 0.3096, Acc : 89.10\n",
            "Step [220/399], Loss: 0.3088, Acc : 89.16\n",
            "Step [240/399], Loss: 0.3022, Acc : 89.27\n",
            "Step [260/399], Loss: 0.3054, Acc : 89.17\n",
            "Step [280/399], Loss: 0.3105, Acc : 89.14\n",
            "Step [300/399], Loss: 0.3099, Acc : 89.17\n",
            "Step [320/399], Loss: 0.3106, Acc : 89.12\n",
            "Step [340/399], Loss: 0.3072, Acc : 89.22\n",
            "Step [360/399], Loss: 0.3095, Acc : 89.06\n",
            "Step [380/399], Loss: 0.3110, Acc : 88.93\n",
            "Validation . . . \n",
            "Loss 0.2045,  Acc 92.53,  IoU 0.2337\n",
            "Testing best epoch . . .\n",
            "Loss 0.0736,  Acc 98.98,  IoU 0.9554\n",
            "Overall performance:\n",
            "Acc: 0.9591836734693877,  IoU: 0.8829589594036342\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mhbokaei/shakouri/test/Satellite/learning/metrics.py:60: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  d['IoU'] = tp / (tp + fp + fn)\n",
            "/home/mhbokaei/shakouri/test/Satellite/learning/metrics.py:61: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  d['Precision'] = tp / (tp + fp)\n",
            "/home/mhbokaei/shakouri/test/Satellite/learning/metrics.py:62: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  d['Recall'] = tp / (tp + fn)\n",
            "/home/mhbokaei/shakouri/test/Satellite/learning/metrics.py:63: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  d['F1-score'] = 2 * tp / (2 * tp + fp + fn)\n"
          ]
        }
      ],
      "source": [
        "args= parser.parse_args(args=[])\n",
        "args= vars(args)\n",
        "for k, v in args.items():\n",
        "        if 'mlp' in k:\n",
        "            v = v.replace('[', '')\n",
        "            v = v.replace(']', '')\n",
        "            args[k] = list(map(int, v.split(',')))\n",
        "\n",
        "pprint.pprint(args)\n",
        "main(args)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
