{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torchnet as tnt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch import Tensor\n",
        "import os\n",
        "import json\n",
        "import pickle as pkl\n",
        "import argparse\n",
        "import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# report from number of pixle for each file\n",
        "def extract_all_pixle(path: str,\n",
        "                      save_fig: str) -> None:\n",
        "    \n",
        "    \"\"\"\"\n",
        "Plot the number of pixel for each sample\n",
        "    \"\"\"\"\"\n",
        "    all_npy_file = get_all_npy(path)\n",
        "    # step 1 -> initialize dictionary for save number of pixle for each file\n",
        "    all_pixle_for_each_file = dict()\n",
        "    \n",
        "    # step 2 -> iterate in files and extract data\n",
        "    for name , path in all_npy_file.items():\n",
        "        pixle = np.load(path).shape[2]\n",
        "        all_pixle_for_each_file.update({int(name) : pixle})\n",
        "        \n",
        "        \n",
        "        # step 2.1 -> sort data based names\n",
        "        all_pixle_for_each_file = dict(\n",
        "            sorted(all_pixle_for_each_file.items(), key=lambda item:item[0])\n",
        "        )\n",
        "    \n",
        "    point_plot(all_pixle_for_each_file,save_fig,\"Sample\",\"Number Of Pixel\",\"Pixel counts\" )\n",
        "\n",
        "\n",
        "def extract_sample_in_pixel(path: str,\n",
        "                      save_fig: str,\n",
        "                      threshold: int ) -> None:\n",
        "    \n",
        "    \"\"\"\"\n",
        "Plot the Number of sample in each pixel\n",
        "threshold: for clustering close groups of number of pix\n",
        "    \"\"\"\"\"\n",
        "    all_npy_file = get_all_npy(path)\n",
        "    # step 1 -> initialize dictionary for save number of pixle for each file\n",
        "    all_pixle_for_each_file = dict() \n",
        "    # step 2 -> iterate in files and extract data\n",
        "    for name , path in all_npy_file.items():\n",
        "        pixle = np.load(path).shape[2]\n",
        "        all_pixle_for_each_file.update({int(name) : pixle})               \n",
        "        # step 2.1 -> sort data based names\n",
        "        all_pixle_for_each_file = dict(\n",
        "            sorted(all_pixle_for_each_file.items(), key=lambda item:item[0])\n",
        "        )\n",
        "  \n",
        "    pixel_counts = list(all_pixle_for_each_file.values())\n",
        "    pixel_frequency = Counter(pixel_counts)\n",
        "    thresholdd = threshold  \n",
        "    grouped_counter = {}\n",
        "    for key, value in pixel_frequency.items():\n",
        "        grouped = False\n",
        "        for group_key in grouped_counter:\n",
        "            if abs(key - group_key) <= thresholdd:\n",
        "                grouped_counter[group_key] += value\n",
        "                grouped = True\n",
        "                break\n",
        "        if not grouped:\n",
        "            grouped_counter[key] = value\n",
        "    grouped_counter = dict(sorted(grouped_counter.items()))  \n",
        "    point_plot(grouped_counter,save_fig,\"Number Of Pixel\",\"Number Of Sample\",\"Number of sample in each pixel\" )\n",
        "\n",
        "\n",
        "\n",
        "def data_len(path: str) -> int:\n",
        "  \"\"\"\"\"\n",
        "  It returns the number of sample\n",
        "  path: path to the dataset befor DATA folder\n",
        "  \"\"\"\"\"\n",
        "  data_folder = os.path.join(path, 'DATA')\n",
        "  l = [f for f in os.listdir(data_folder) if f.endswith('.npy')]\n",
        "  pid = [int(f.split('.')[0]) for f in l]\n",
        "  pid = list(np.sort(pid))\n",
        "  pid = list(map(str, pid))\n",
        "  len_data = len(pid) \n",
        "  return len_data\n",
        "\n",
        "\n",
        "def data_check(path: str) -> None:\n",
        "  \"\"\"\"\"\n",
        "  It checks the shape of each sample (it must be 3 dimension),\n",
        "   dimension 0 must be 24 and dimension 1 must be 10 \n",
        "  path: path to the dataset befor DATA folder\n",
        "  \"\"\"\"\"\n",
        "  data_folder = os.path.join(path, 'DATA')\n",
        "  l = [f for f in os.listdir(data_folder) if f.endswith('.npy')]\n",
        "  pid = [int(f.split('.')[0]) for f in l]\n",
        "  pid = list(np.sort(pid))\n",
        "  pid = list(map(str, pid))\n",
        "  len_data = len(pid) \n",
        "  for item in range(len_data):\n",
        "    #print(\"pid[item]: \", pid[item])\n",
        "    x0 = np.load(os.path.join(path, 'DATA', '{}.npy'.format(pid[item])))  ##it returns Sample\n",
        "    if x0.ndim != 3:\n",
        "      print(\"Bpixel: \", pid[item], \", x0.shape: \", x0.shape, \", x0.ndim: \", x0.ndim)\n",
        "    if x0.shape[0] != 55 or x0.shape[1] != 4:\n",
        "      print(\"Bpixel: \", pid[item], \", x0.shape[0]: \", x0.shape[0], \", x0.shape[1]: \", x0.shape[1])\n",
        "\n",
        "\n",
        "def get_all_npy(path : str) -> dict:\n",
        "    \"\"\"\"\"\n",
        "Load All data from the path  \n",
        "path: path to the source of data (get .npy in this path)\n",
        "    \"\"\"\"\"   \n",
        "    files = dict()\n",
        "    for root, dir , _files in os.walk(path):\n",
        "        for file in _files:\n",
        "            if file.endswith(\".npy\"):\n",
        "                name = file.split(\".npy\")[0]\n",
        "                files[name] = os.path.join(root, file) \n",
        "    return files\n",
        "\n",
        "\n",
        "def remove_dim(dim: int,\n",
        "                npy_files : list,\n",
        "                list_spec : list) -> np.array:\n",
        "    \"\"\"\"\"\n",
        "dim: which dimension to remove(0:date,  1:spec, 2:pixel)\n",
        "It takes the list of spectrum then remove them\n",
        "npy_files: Source data which comes from def get_all_npy \n",
        "list_spec:  list of spectrum which removes\n",
        "    \"\"\"\"\"\n",
        "    files_result = {}\n",
        "    for name , npy_files in npy_files.items():\n",
        "        data = np.load(npy_files)\n",
        "        delsp = np.delete(data, list_spec, axis=dim)  # Delete along axis 1 (columns)\n",
        "        files_result[name] = delsp\n",
        "    return files_result\n",
        "\n",
        "def elminate_date(npy_files : list,\n",
        "                 list_dates : list) -> np.array:\n",
        "    \"\"\"\"\"\n",
        "It takes the list of data and then zeros out the required dates\n",
        "npy_files: Source data which comes from def get_all_npy \n",
        "list_dates:  list of dates which turns to zeros\n",
        "    \"\"\"\"\"\n",
        "    files_result = {}\n",
        "    for name , npy_file in npy_files.items():\n",
        "        data = np.load(npy_file)\n",
        "        for date in list_dates:\n",
        "            matrix_date = data[date]\n",
        "            data[date] = np.zeros(matrix_date.shape)\n",
        "        files_result[name] = data\n",
        "    return files_result\n",
        "\n",
        "\n",
        "def remove_dimension(dim:int,\n",
        "                    list_spec: list,\n",
        "                    path_source: str,\n",
        "                    path_Rsave: str) -> None:\n",
        "    \"\"\"\"\"\n",
        "dim: which dimension to remove(0:date,  1:spec, 2:pixel)\n",
        "It takes the list of spectrum then remove them with save the result\n",
        "list_spec:  list of spectrum which removes\n",
        "path_source:  path to the source of data (get .npy in this path)\n",
        "path_Rsave: path to create and save results (save .npy in this path)\n",
        "    \"\"\"\"\"\n",
        "    os.makedirs(path_Rsave, exist_ok=True)\n",
        "    npy_files = get_all_npy(path_source)\n",
        "    x = remove_dim(dim,npy_files,list_spec)\n",
        "    for file in x:\n",
        "        path = os.path.join(path_Rsave, '{}.npy'.format(file))\n",
        "        np.save(path, x[file])\n",
        "\n",
        "def remove_dimension_pkl(dim:int,\n",
        "                    list_spec,\n",
        "                    path_source: str,\n",
        "                    path_Rsave: str) -> None:\n",
        "    \"\"\"\"\"\n",
        "dim: which dimension to remove(0:date,  1:spec)\n",
        "It takes the list of dates and spectrum then remove them with save the result\n",
        "list_spec:  list of spectrum or dates which removes\n",
        "path_source:  path to the source of data (get .pkl in this path)\n",
        "path_Rsave: path to create and save results (save .pkl in this path)\n",
        "    \"\"\"\"\"\n",
        "    os.makedirs(path_Rsave, exist_ok=True)\n",
        "    load_pkl=  pkl.load(open( path_source, 'rb'))\n",
        "    load_pkl_li = list(load_pkl)\n",
        "    del_0 = np.delete(load_pkl_li[0], list_spec, axis=dim)\n",
        "    load_pkl_li[0] = del_0\n",
        "    del_1 = np.delete(load_pkl_li[1], list_spec, axis=dim)\n",
        "    load_pkl_li[1] = del_1\n",
        "    load_pkl_tu = tuple(load_pkl_li)\n",
        "    pkl.dump(load_pkl_tu, open(os.path.join(path_Rsave,'s2_pkl.pkl'), 'wb'))\n",
        "\n",
        "\n",
        "def zero_pad(list_dates: list,\n",
        "             path_source: str,\n",
        "             path_Rsave: str) -> None:\n",
        "    \"\"\"\"\"\n",
        "For zero padding of specific dates with save the result\n",
        "list_dates:  list of dates which turns to zeros\n",
        "path_source:  path to the source of data (get .npy in this path)\n",
        "path_Rsave: path to create and save results (save .npy in this path)\n",
        "    \"\"\"\"\"\n",
        "    os.makedirs(path_Rsave, exist_ok=True)\n",
        "    npy_files = get_all_npy(path_source)\n",
        "    x = elminate_date(npy_files, list_dates)\n",
        "    for file in x:\n",
        "        path = os.path.join(path_Rsave, '{}.npy'.format(file))\n",
        "        np.save(path, x[file])\n",
        "\n",
        "def point_plot(data,\n",
        "               path : str,\n",
        "               x_lable : str,\n",
        "               y_lable : str,\n",
        "               title : str):\n",
        "    \"\"\"\"\"\"\"\"\"\"\n",
        "It is used for general Plot\n",
        "    \"\"\"\"\"\"\"\"\"  \n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    x = list(data.keys())\n",
        "    y = list(data.values())\n",
        "    x = list(map(lambda x : str(x), x))\n",
        "\n",
        "    for _x, _y in zip(x, y):\n",
        "        plt.text(_x, _y, f'{_y:.0f}', fontsize=9, ha='center', va='bottom')\n",
        "    plt.plot(x, y, marker='o', linestyle='--')\n",
        "    plt.xlabel(x_lable)\n",
        "    plt.ylabel(y_lable)\n",
        "    plt.title(title)\n",
        "    plt.grid(True)\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def split_data_labels(path_source: str,\n",
        "                      path_Rsave: str,\n",
        "                      labels: str) -> None:\n",
        "    \"\"\"\"\"\n",
        "Split sample in diffrent folder by they labels name\n",
        "labels:  label_19class  or  label_44class\n",
        "path_source:  path to the source of data (get befor DATA in this path)\n",
        "path_Rsave: path to create and save results (get befor DATA in this path))\n",
        "    \"\"\"\"\"                      \n",
        "    data_folder = os.path.join(path_source, 'DATA')\n",
        "    meta_folder = os.path.join(path_source, 'META')\n",
        "    data_folder1 = os.path.join(path_Rsave, 'DATA')\n",
        "    sub_classes = None\n",
        "\n",
        "    npy_files = [f for f in os.listdir(data_folder) if f.endswith('.npy')]\n",
        "    npy_names = [f.split(\".\")[0] for f in npy_files]\n",
        "    npy_names.sort(key=lambda x: int(x))\n",
        "    # Load labels from JSON file\n",
        "    with open(os.path.join(meta_folder, 'labels.json'), 'r') as f:\n",
        "        labels_data = json.load(f)\n",
        "        labels_dict = labels_data[labels]\n",
        "    # Create a dictionary to store npy data based on labels\n",
        "    grouped_npy = {}\n",
        "    # Iterate through npy files and their corresponding labels\n",
        "    for npy_name in npy_names:\n",
        "        label = labels_dict[npy_name]\n",
        "        # Filter based on sub_classes (optional)\n",
        "        if sub_classes is not None and label not in sub_classes:\n",
        "            continue\n",
        "        # Group npy data by label\n",
        "        if label not in grouped_npy:\n",
        "            grouped_npy[label] = []\n",
        "        grouped_npy[label].append(npy_name)\n",
        "    # Create folders for each label group and save npy files\n",
        "    for label, npy_names in grouped_npy.items():\n",
        "        label_folder = os.path.join(data_folder1, str(label))\n",
        "        if not os.path.exists(label_folder):\n",
        "            os.makedirs(label_folder)\n",
        "        for npy_name in npy_names:\n",
        "        # Construct original and new paths\n",
        "            npy_path = os.path.join(data_folder, npy_name + \".npy\")\n",
        "            new_npy_path = os.path.join(label_folder, npy_name + \".npy\")\n",
        "        # Copy the npy file\n",
        "            with open(npy_path, 'rb') as src, open(new_npy_path, 'wb') as dst:\n",
        "                shutil.copyfileobj(src, dst)\n",
        "    print(\"Successfully grouped and saved npy files based on labels.\")\n",
        "\n",
        "def labels_count(path: str,\n",
        "                 classes: str):\n",
        "  \"\"\"\"\"\n",
        "  It returns the number of sample in each classes\n",
        "  path: path to the .JSON\n",
        "  classes: 'label_51class'\n",
        "  \"\"\"\"\"\n",
        "  with open( path , 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "  label_counts = {}\n",
        "  for label, count in data[classes].items():\n",
        "    if count in label_counts:\n",
        "        label_counts[count] += 1\n",
        "    else:\n",
        "        label_counts[count] = 1\n",
        "\n",
        "  label_counts = dict(sorted(label_counts.items(), key=lambda item:item[0]))\n",
        "  for count, num_instances in label_counts.items():\n",
        "    print(f\"label {count}: {num_instances}\")\n",
        "\n",
        "\n",
        "####for labels count. with DATA folder and labels.json### use \"Data_distribution\"#####\n",
        "def point_plot2(data,\n",
        "               D_list,  ##List of deleted classes\n",
        "               path : str,\n",
        "               x_labels_list: list, \n",
        "               x_lable : str,\n",
        "               y_lable : str,\n",
        "               title : str):\n",
        "    \n",
        "    for i in D_list:\n",
        "     del data[i]\n",
        "    \n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    x = list(data.keys())\n",
        "    y = list(data.values())\n",
        "    x = list(map(lambda x : str(x), x))\n",
        "\n",
        "    for _x, _y in zip(x, y):\n",
        "        plt.text(_x, _y, f'{_y:.0f}', fontsize=9, ha='center', va='bottom')\n",
        "    plt.plot(x, y, marker='o', linestyle='--')\n",
        "    plt.xticks(x, x_labels_list)\n",
        "    plt.xlabel(x_lable)\n",
        "    plt.ylabel(y_lable)\n",
        "    plt.title(title)\n",
        "    plt.grid(True)\n",
        "    plt.savefig(path)\n",
        "    print(\"data.keys():\", data.keys())\n",
        "    print(\"len(data.keys()):\", len(data.keys()))\n",
        "    #plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def Data_distribution(dataset_folder, label_class, res_dir, Delet_label_class, x_labels_list ):\n",
        "\n",
        "    \"\"\"\"\"\n",
        "    It returns the number of sample in each classes. sample must be in DATA folder\n",
        "    dataset_folder: path dataset before DATA and META\n",
        "    label_class: 'label_51class'\n",
        "    res_dir: save result direction\n",
        "    Delet_label_class: do not count deleted labels\n",
        "    x_labels_list: real name of each labels\n",
        "    \"\"\"\"\"\n",
        "\n",
        "    if not os.path.exists(res_dir):\n",
        "        os.makedirs(res_dir)\n",
        "\n",
        "    data_folder = os.path.join(dataset_folder , 'DATA')\n",
        "    l = [f for f in os.listdir(data_folder) if f.endswith('.npy')]\n",
        "    pid = [int(f.split('.')[0]) for f in l]\n",
        "    pid = list(np.sort(pid))\n",
        "\n",
        "    with open(os.path.join(dataset_folder, 'META', 'labels.json'), 'r') as file:\n",
        "        data = json.load(file)\n",
        "    Dic = data[label_class]\n",
        "    converted_Dic = {int(key): value for key, value in Dic.items()}\n",
        "    Final_dic = {key: converted_Dic[key] for key in pid if key in converted_Dic}\n",
        "\n",
        "    class_19_44 = list(Final_dic.values())\n",
        "    counter = {}\n",
        "    for _class in class_19_44:\n",
        "        if _class in counter:\n",
        "            counter[_class] += 1\n",
        "        elif _class not in counter:\n",
        "            counter[_class] = 0\n",
        "    counter = dict(sorted(counter.items(), key=lambda item:item[0]))\n",
        "    save_path_cn = os.path.join(res_dir, \"number_of_classes.png\")\n",
        "    point_plot2(counter,Delet_label_class, save_path_cn,x_labels_list, \"Classes\", \"Number\", \"Number of each class\")\n",
        "    for count, num_instances in counter.items():\n",
        "        print(f\"label {count}: {num_instances}\")\n",
        "\n",
        "########################################\n",
        "def split_data_test_train_flat(path_source: str, path_Rsave: str, labels: str, test_ratio: float, seed: int) -> None:\n",
        "\n",
        "    \"\"\"\"\"\n",
        "    split data from each classes\n",
        "    path_source: path dataset before DATA and META\n",
        "    path_Rsave: save result direction\n",
        "    labels: 'label_51class'\n",
        "    test_ratio: ratio of split\n",
        "    seed: seed\n",
        "    \"\"\"\"\"\n",
        "    random.seed(seed)\n",
        "    data_folder = os.path.join(path_source, 'DATA')\n",
        "    meta_folder = os.path.join(path_source, 'META')\n",
        "    data_folder1 = os.path.join(path_Rsave, 'DATA')\n",
        "    sub_classes = None\n",
        "\n",
        "    npy_files = [f for f in os.listdir(data_folder) if f.endswith('.npy')]\n",
        "    npy_names = [f.split(\".\")[0] for f in npy_files]\n",
        "    npy_names.sort(key=lambda x: int(x))\n",
        "\n",
        "    with open(os.path.join(meta_folder, 'labels.json'), 'r') as f:\n",
        "        labels_data = json.load(f)\n",
        "        labels_dict = labels_data[labels]\n",
        "\n",
        "    for npy_name in npy_names:\n",
        "        label = labels_dict[npy_name]\n",
        "        if sub_classes is not None and label not in sub_classes:\n",
        "            continue\n",
        "\n",
        "        if random.random() < test_ratio:\n",
        "            dest_folder = os.path.join(path_Rsave, 'test')\n",
        "        else:\n",
        "            dest_folder = os.path.join(path_Rsave, 'train')\n",
        "\n",
        "        if not os.path.exists(dest_folder):\n",
        "            os.makedirs(dest_folder)\n",
        "\n",
        "        npy_path = os.path.join(data_folder, npy_name + \".npy\")\n",
        "        new_npy_path = os.path.join(dest_folder, npy_name + \".npy\")\n",
        "        with open(npy_path, 'rb') as src, open(new_npy_path, 'wb') as dst:\n",
        "            shutil.copyfileobj(src, dst)\n",
        "\n",
        "    print(\"Successfully split and saved npy files into test and train folders without subdirectories based on labels and specified ratio.\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = r\"C:\\Users\\HA\\Desktop\\e\\RS\\sattelate\\dataset_folder\\DATA\"\n",
        "save_fig = r\"C:\\Users\\HA\\Desktop\\e\\RS\\sattelate\\erfanplottttt\"\n",
        "threshold = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "extract_sample_in_pixel(path,save_fig,threshold )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
