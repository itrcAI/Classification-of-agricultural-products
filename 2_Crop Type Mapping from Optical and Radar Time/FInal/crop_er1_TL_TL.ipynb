{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchnet as tnt\n",
        "# from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import os\n",
        "import json\n",
        "import pickle as pkl\n",
        "import argparse\n",
        "import pprint\n",
        "from datetime import datetime\n",
        "\n",
        "from models.stclassifier_fusion import PseTae\n",
        "from dataset_fusion import PixelSetData, PixelSetData_preloaded\n",
        "from learning.focal_loss import FocalLoss\n",
        "from learning.weight_init import weight_init\n",
        "from learning.metrics import mIou, confusion_matrix_analysis\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, optimizer, criterion, data_loader, device, args):\n",
        "    start = datetime.now()\n",
        "    acc_meter = tnt.meter.ClassErrorMeter(accuracy=True)\n",
        "    loss_meter = tnt.meter.AverageValueMeter()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for i, (x, x2, y, dates) in enumerate(data_loader): \n",
        "                \n",
        "        y_true.extend(list(map(int, y)))\n",
        "\n",
        "        x = recursive_todevice(x, device)\n",
        "        x2 = recursive_todevice(x2, device) \n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x, x2, dates)\n",
        "        loss = criterion(out, y.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = out.detach()\n",
        "        y_p = pred.argmax(dim=1).cpu().numpy()\n",
        "        y_pred.extend(list(y_p))\n",
        "        acc_meter.add(pred, y)\n",
        "        loss_meter.add(loss.item())\n",
        "\n",
        "        if (i + 1) % args['display_step'] == 0:\n",
        "            print('Step [{}/{}], Loss: {:.4f}, Acc : {:.2f}'.format(i + 1, len(data_loader), loss_meter.value()[0],\n",
        "                                                                    acc_meter.value()[0]))\n",
        "\n",
        "    epoch_metrics = {'train_loss': loss_meter.value()[0],\n",
        "                     'train_accuracy': acc_meter.value()[0],\n",
        "                     'train_IoU': mIou(y_true, y_pred, n_classes=args['num_classes'])}\n",
        "    print('train epoch complete in ----------------------->', datetime.now()-start)\n",
        "    return epoch_metrics\n",
        "\n",
        "\n",
        "def evaluation(model, criterion, loader, device, args, mode='val'):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    acc_meter = tnt.meter.ClassErrorMeter(accuracy=True)\n",
        "    loss_meter = tnt.meter.AverageValueMeter()\n",
        "\n",
        "    for (x, x2, y, dates) in loader: \n",
        "\n",
        "        y_true.extend(list(map(int, y)))\n",
        "\n",
        "        x = recursive_todevice(x, device)\n",
        "        x2 = recursive_todevice(x2, device) #add x2 to device\n",
        "        y = y.to(device)\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prediction = model(x, x2, dates)  \n",
        "            loss = criterion(prediction, y)\n",
        "\n",
        "        acc_meter.add(prediction, y)\n",
        "        loss_meter.add(loss.item())\n",
        "\n",
        "        y_p = prediction.argmax(dim=1).cpu().numpy()\n",
        "        y_pred.extend(list(y_p))\n",
        "\n",
        "    metrics = {'{}_accuracy'.format(mode): acc_meter.value()[0],\n",
        "               '{}_loss'.format(mode): loss_meter.value()[0],\n",
        "               '{}_IoU'.format(mode): mIou(y_true, y_pred, args['num_classes'])}\n",
        "\n",
        "    if mode == 'val':\n",
        "        return metrics\n",
        "    elif mode == 'test':\n",
        "        return metrics, confusion_matrix(y_true, y_pred, labels=list(range(args['num_classes']))), y_true, y_pred \n",
        "\n",
        "\n",
        "def get_pse(folder, args):\n",
        "    if args['preload']:\n",
        "        dt = PixelSetData_preloaded(args[folder], labels='label_19class', npixel=args['npixel'],\n",
        "                          sub_classes = None,\n",
        "                          norm=None,\n",
        "                          minimum_sampling=args['minimum_sampling'],\n",
        "                          fusion_type = args['fusion_type'], interpolate_method = args['interpolate_method'],\n",
        "                          extra_feature='geomfeat' if args['geomfeat'] else None,  \n",
        "                          jitter=None)\n",
        "    else:\n",
        "        dt = PixelSetData(args[folder], labels='label_19class', npixel=args['npixel'],\n",
        "                          sub_classes = None,\n",
        "                          norm=None,\n",
        "                          minimum_sampling=args['minimum_sampling'],\n",
        "                          fusion_type = args['fusion_type'], interpolate_method = args['interpolate_method'],\n",
        "                          extra_feature='geomfeat' if args['geomfeat'] else None,  \n",
        "                          jitter=None)\n",
        "    return dt\n",
        "\n",
        "def get_loaders(args):\n",
        "    loader_seq =[]\n",
        "    train_dataset = get_pse('dataset_folder', args)\n",
        "    val_dataset = get_pse('val_folder', args)\n",
        "    test_dataset = get_pse('test_folder', args)\n",
        "\n",
        "    if args['dataset_folder2'] is not None:\n",
        "        train_dataset2 = get_pse('dataset_folder2', args)\n",
        "        train_dataset = data.ConcatDataset([train_dataset, train_dataset2])\n",
        "\n",
        "        \n",
        "    train_loader = data.DataLoader(train_dataset, batch_size=args['batch_size'],\n",
        "                                        num_workers=args['num_workers'], shuffle = True, pin_memory =True) \n",
        "\n",
        "    validation_loader = data.DataLoader(val_dataset, batch_size=args['batch_size'],\n",
        "                                        num_workers=args['num_workers'], shuffle = False, pin_memory = True)\n",
        "\n",
        "    test_loader = data.DataLoader(test_dataset, batch_size=args['batch_size'],\n",
        "                                    num_workers=args['num_workers'], shuffle = False, pin_memory =True)\n",
        "\n",
        "    loader_seq.append((train_loader, validation_loader, test_loader))\n",
        "    return loader_seq\n",
        "\n",
        "def recursive_todevice(x, device):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x.to(device)\n",
        "    else:\n",
        "        return [recursive_todevice(c, device) for c in x]\n",
        "\n",
        "\n",
        "def prepare_output(args):\n",
        "    os.makedirs(args['res_dir'], exist_ok=True)\n",
        "\n",
        "\n",
        "def checkpoint(log, args):\n",
        "    with open(os.path.join(args['res_dir'], 'trainlog.json'), 'w') as outfile:\n",
        "        json.dump(log, outfile, indent=4)\n",
        "\n",
        "\n",
        "def save_results(metrics, conf_mat, args, y_true, y_pred):\n",
        "    with open(os.path.join(args['res_dir'], 'test_metrics.json'), 'w') as outfile:\n",
        "        json.dump(metrics, outfile, indent=4)\n",
        "    pkl.dump(conf_mat, open(os.path.join(args['res_dir'], 'conf_mat.pkl'), 'wb'))\n",
        "\n",
        "\n",
        "    # save y_true, y_pred\n",
        "    pkl.dump(y_true, open(os.path.join(args['res_dir'], 'y_true_test_data.pkl'), 'wb'))\n",
        "    pkl.dump(y_pred, open(os.path.join(args['res_dir'], 'y_pred_test_data.pkl'), 'wb'))\n",
        "\n",
        "    # ----> save confusion matrix \n",
        "    plt.figure(figsize=(15,10))\n",
        "    img = sns.heatmap(conf_mat, annot = True, fmt='d',linewidths=0.5, cmap='OrRd')\n",
        "    img.tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
        "    img.set(ylabel=\"True Label\", xlabel=\"Predicted Label\")\n",
        "    img.figure.savefig(os.path.join(args['res_dir'], 'conf_mat_picture.png'))\n",
        "    img.get_figure().clf()\n",
        "\n",
        "\n",
        "def overall_performance(args):\n",
        "    cm = np.zeros((args['num_classes'], args['num_classes']))\n",
        "    cm += pkl.load(open(os.path.join(args['res_dir'], 'conf_mat.pkl'), 'rb'))\n",
        "    per_class, perf = confusion_matrix_analysis(cm)\n",
        "\n",
        "    print('Overall performance:')\n",
        "    print('Acc: {},  IoU: {}'.format(perf['Accuracy'], perf['MACRO_IoU']))\n",
        "\n",
        "    with open(os.path.join(args['res_dir'], 'overall.json'), 'w') as file:\n",
        "        file.write(json.dumps(perf, indent=4))\n",
        "    with open(os.path.join(args['res_dir'], 'per_class.json'), 'w') as file:\n",
        "        file.write(json.dumps(per_class, indent=4))\n",
        "\n",
        "\n",
        "def plot_metrics(args):\n",
        "    with open(os.path.join(args['res_dir'], 'trainlog.json'), 'r') as file:\n",
        "        d = json.loads(file.read())\n",
        "    \n",
        "    epoch = [i+1 for i in range(len(d))]\n",
        "    train_loss = [d[str(i+1)][\"train_loss\"] for i in range(len(d))]\n",
        "    val_loss = [d[str(i+1)][\"val_loss\"] for i in range(len(d))]\n",
        "    train_acc = [d[str(i+1)][\"train_accuracy\"] for i in range(len(d))]\n",
        "    val_acc = [d[str(i+1)][\"val_accuracy\"] for i in range(len(d))]\n",
        "\n",
        "    # plot loss/accuracy\n",
        "    plt.title('monitoring metrics - loss')\n",
        "    plt.plot(epoch, train_loss, label = \"train_loss\")\n",
        "    plt.plot(epoch,val_loss, label = \"val_loss\")\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(args['res_dir'], 'loss_graph.png'))\n",
        "    plt.clf()\n",
        "\n",
        "    plt.title('monitoring metrics - accuracy')\n",
        "    plt.plot(epoch, train_acc, label = \"train_accuracy\")\n",
        "    plt.plot(epoch,val_acc, label = \"val_accuracy\")\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(args['res_dir'], 'accuracy_graph.png'))\n",
        "    plt.clf()\n",
        "    #---------------------------------------------\n",
        "\n",
        "def main(args):\n",
        "    np.random.seed(args['rdm_seed'])\n",
        "    torch.manual_seed(args['rdm_seed'])\n",
        "    prepare_output(args)\n",
        "\n",
        "    extra = 'geomfeat' if args['geomfeat'] else None\n",
        "\n",
        "    device = torch.device(args['device'])\n",
        "\n",
        "    loaders = get_loaders(args)\n",
        "    for _, (train_loader, val_loader, test_loader) in enumerate(loaders):\n",
        "        print('Train {}, Val {}, Test {}'.format(len(train_loader), len(val_loader), len(test_loader)))\n",
        "\n",
        "        model_args = dict(input_dim=args['input_dim'], mlp1=args['mlp1'], pooling=args['pooling'],\n",
        "                            mlp2=args['mlp2'], n_head=args['n_head'], d_k=args['d_k'], mlp3=args['mlp3'],\n",
        "                            dropout=args['dropout'], T=args['T'], len_max_seq=args['lms'],\n",
        "                            positions=None, fusion_type = args['fusion_type'],\n",
        "                            mlp4=args['mlp4'])\n",
        "\n",
        "        if args['geomfeat']:\n",
        "            model_args.update(with_extra=True, extra_size=4) \n",
        "        else:\n",
        "            model_args.update(with_extra=False, extra_size=None)\n",
        "\n",
        "        \n",
        "        model = PseTae(**model_args)\n",
        "                ###############Freeze Layers (TL)###############\n",
        "        model.load_state_dict(\n",
        "            torch.load(os.path.join(args['res_dir_WE'], 'model.pth.tar'))['state_dict'])  \n",
        "        #model_weights = model.state_dict()\n",
        "        #print(\"model_weights:\", model_weights)\n",
        "        #first_layer_weights = model_weights['temporal_encoder.inlayernorm.weight']  \n",
        "        #print(\"first_layer_weights_firstload:\", first_layer_weights)\n",
        "        sum_model = summary(model)\n",
        "        print(\"Summary of the model_beforfreez: \",sum_model )\n",
        "\n",
        "        for param in model.spatial_encoder_earlyFusion.parameters(): \n",
        "         param.requires_grad = False\n",
        "        sum_model = summary(model)\n",
        "        print(\"Summary of the model_AfterFreez1: \",sum_model )\n",
        "        for param in model.temporal_encoder_earlyFusion.parameters():  \n",
        "         param.requires_grad = False\n",
        "         \n",
        "        sum_model = summary(model)\n",
        "        print(\"Summary of the model_AfterFreez2: \",sum_model )\n",
        "        ####################################\n",
        "        print(model.param_ratio())\n",
        "        model = model.to(device)\n",
        "        #model.apply(weight_init)\n",
        "        ##################end##################\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters())\n",
        "        criterion = FocalLoss(args['gamma'])\n",
        "\n",
        "        trainlog = {}\n",
        "\n",
        "\n",
        "        best_mIoU = 0\n",
        "        for epoch in range(1, args['epochs'] + 1):\n",
        "            print('EPOCH {}/{}'.format(epoch, args['epochs']))\n",
        "\n",
        "            model.train()\n",
        "            train_metrics = train_epoch(model, optimizer, criterion, train_loader, device=device, args=args)\n",
        "\n",
        "            print('Validation . . . ')\n",
        "            model.eval()\n",
        "            val_metrics = evaluation(model, criterion, val_loader, device=device, args=args, mode='val')\n",
        "\n",
        "            print('Loss {:.4f},  Acc {:.2f},  IoU {:.4f}'.format(val_metrics['val_loss'], val_metrics['val_accuracy'],\n",
        "                                                                 val_metrics['val_IoU']))\n",
        "\n",
        "            trainlog[epoch] = {**train_metrics, **val_metrics}\n",
        "            checkpoint(trainlog, args)\n",
        "\n",
        "            if val_metrics['val_IoU'] >= best_mIoU:\n",
        "                best_mIoU = val_metrics['val_IoU']\n",
        "                torch.save({'epoch': epoch, 'state_dict': model.state_dict(),\n",
        "                            'optimizer': optimizer.state_dict()},\n",
        "                           os.path.join(args['res_dir'], 'model.pth.tar'))\n",
        "\n",
        "        print('Testing best epoch . . .')\n",
        "        model.load_state_dict(\n",
        "            torch.load(os.path.join(args['res_dir'],  'model.pth.tar'))['state_dict'])\n",
        "        model.eval()\n",
        "\n",
        "        test_metrics, conf_mat, y_true, y_pred = evaluation(model, criterion, test_loader, device=device, mode='test', args=args) \n",
        "\n",
        "        print('Loss {:.4f},  Acc {:.2f},  IoU {:.4f}'.format(test_metrics['test_loss'], test_metrics['test_accuracy'],\n",
        "                                                             test_metrics['test_IoU']))\n",
        "                                                             \n",
        "        save_results(test_metrics, conf_mat, args, y_true, y_pred) \n",
        "\n",
        "        \n",
        "        #model_weights =model\n",
        "        #print(\"first_layer_weights_after init:\", model_weights)   \n",
        "\n",
        "    overall_performance(args)\n",
        "    plot_metrics(args)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'T': 1000,\n",
            " 'batch_size': 32,\n",
            " 'd_k': 32,\n",
            " 'dataset_folder': '/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/dataset_folder/s1_data',\n",
            " 'dataset_folder2': None,\n",
            " 'device': 'cuda',\n",
            " 'display_step': 50,\n",
            " 'dropout': 0.2,\n",
            " 'epochs': 3,\n",
            " 'fusion_type': 'tsa',\n",
            " 'gamma': 1,\n",
            " 'geomfeat': 1,\n",
            " 'input_dim': 10,\n",
            " 'interpolate_method': 'nn',\n",
            " 'lms': None,\n",
            " 'lr': 0.001,\n",
            " 'minimum_sampling': None,\n",
            " 'mlp1': [10, 32, 64],\n",
            " 'mlp2': [132, 128],\n",
            " 'mlp3': [512, 128, 128],\n",
            " 'mlp4': [256, 64, 32, 19],\n",
            " 'n_head': 4,\n",
            " 'npixel': 5,\n",
            " 'num_classes': 19,\n",
            " 'num_workers': 8,\n",
            " 'pooling': 'mean_std',\n",
            " 'positions': 'bespoke',\n",
            " 'preload': False,\n",
            " 'rdm_seed': 1,\n",
            " 'res_dir': './results_TL',\n",
            " 'res_dir_WE': './results_WE',\n",
            " 'test_folder': '/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/test_folder/s1_data',\n",
            " 'val_folder': '/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/val_folder/s1_data'}\n",
            "Train 4, Val 4, Test 4\n",
            "Summary of the model_beforfreez:  ===========================================================================\n",
            "Layer (type:depth-idx)                             Param #\n",
            "===========================================================================\n",
            "PseTae                                             --\n",
            "├─PixelSetEncoder: 1-1                             --\n",
            "│    └─Sequential: 2-1                             --\n",
            "│    │    └─linlayer: 3-1                          480\n",
            "│    │    └─linlayer: 3-2                          2,240\n",
            "│    └─Sequential: 2-2                             --\n",
            "│    │    └─Linear: 3-3                            17,024\n",
            "│    │    └─BatchNorm1d: 3-4                       256\n",
            "├─TemporalAttentionEncoder: 1-2                    --\n",
            "│    └─Embedding: 2-3                              (3,584)\n",
            "│    └─LayerNorm: 2-4                              256\n",
            "│    └─LayerNorm: 2-5                              256\n",
            "│    └─MultiHeadAttention: 2-6                     --\n",
            "│    │    └─Linear: 3-5                            16,512\n",
            "│    │    └─Linear: 3-6                            16,512\n",
            "│    │    └─Sequential: 3-7                        16,768\n",
            "│    │    └─ScaledDotProductAttention: 3-8         --\n",
            "│    └─Sequential: 2-7                             --\n",
            "│    │    └─Linear: 3-9                            65,664\n",
            "│    │    └─BatchNorm1d: 3-10                      256\n",
            "│    │    └─ReLU: 3-11                             --\n",
            "│    │    └─Linear: 3-12                           16,512\n",
            "│    │    └─BatchNorm1d: 3-13                      256\n",
            "│    │    └─ReLU: 3-14                             --\n",
            "│    └─Dropout: 2-8                                --\n",
            "├─PixelSetEncoder: 1-3                             --\n",
            "│    └─Sequential: 2-9                             --\n",
            "│    │    └─linlayer: 3-15                         416\n",
            "│    │    └─linlayer: 3-16                         2,240\n",
            "│    └─Sequential: 2-10                            --\n",
            "│    │    └─Linear: 3-17                           17,024\n",
            "│    │    └─BatchNorm1d: 3-18                      256\n",
            "├─PixelSetEncoder: 1-4                             --\n",
            "│    └─Sequential: 2-11                            --\n",
            "│    │    └─linlayer: 3-19                         160\n",
            "│    │    └─linlayer: 3-20                         2,240\n",
            "│    └─Sequential: 2-12                            --\n",
            "│    │    └─Linear: 3-21                           17,024\n",
            "│    │    └─BatchNorm1d: 3-22                      256\n",
            "├─TemporalAttentionEncoder: 1-5                    --\n",
            "│    └─Embedding: 2-13                             (7,168)\n",
            "│    └─LayerNorm: 2-14                             512\n",
            "│    └─LayerNorm: 2-15                             512\n",
            "│    └─MultiHeadAttention: 2-16                    --\n",
            "│    │    └─Linear: 3-23                           32,896\n",
            "│    │    └─Linear: 3-24                           32,896\n",
            "│    │    └─Sequential: 3-25                       16,768\n",
            "│    │    └─ScaledDotProductAttention: 3-26        --\n",
            "│    └─Sequential: 2-17                            --\n",
            "│    │    └─Linear: 3-27                           524,800\n",
            "│    │    └─BatchNorm1d: 3-28                      1,024\n",
            "│    │    └─ReLU: 3-29                             --\n",
            "│    │    └─Linear: 3-30                           131,328\n",
            "│    │    └─BatchNorm1d: 3-31                      512\n",
            "│    │    └─ReLU: 3-32                             --\n",
            "│    └─Dropout: 2-18                               --\n",
            "├─TemporalAttentionEncoder: 1-6                    --\n",
            "│    └─Embedding: 2-19                             (3,584)\n",
            "│    └─LayerNorm: 2-20                             256\n",
            "│    └─LayerNorm: 2-21                             256\n",
            "│    └─MultiHeadAttention: 2-22                    --\n",
            "│    │    └─Linear: 3-33                           16,512\n",
            "│    │    └─Linear: 3-34                           16,512\n",
            "│    │    └─Sequential: 3-35                       16,768\n",
            "│    │    └─ScaledDotProductAttention: 3-36        --\n",
            "│    └─Sequential: 2-23                            --\n",
            "│    │    └─Linear: 3-37                           65,664\n",
            "│    │    └─BatchNorm1d: 3-38                      256\n",
            "│    │    └─ReLU: 3-39                             --\n",
            "│    │    └─Linear: 3-40                           16,512\n",
            "│    │    └─BatchNorm1d: 3-41                      256\n",
            "│    │    └─ReLU: 3-42                             --\n",
            "│    └─Dropout: 2-24                               --\n",
            "├─TemporalAttentionEncoder: 1-7                    --\n",
            "│    └─Embedding: 2-25                             (9,728)\n",
            "│    └─LayerNorm: 2-26                             256\n",
            "│    └─LayerNorm: 2-27                             256\n",
            "│    └─MultiHeadAttention: 2-28                    --\n",
            "│    │    └─Linear: 3-43                           16,512\n",
            "│    │    └─Linear: 3-44                           16,512\n",
            "│    │    └─Sequential: 3-45                       16,768\n",
            "│    │    └─ScaledDotProductAttention: 3-46        --\n",
            "│    └─Sequential: 2-29                            --\n",
            "│    │    └─Linear: 3-47                           65,664\n",
            "│    │    └─BatchNorm1d: 3-48                      256\n",
            "│    │    └─ReLU: 3-49                             --\n",
            "│    │    └─Linear: 3-50                           16,512\n",
            "│    │    └─BatchNorm1d: 3-51                      256\n",
            "│    │    └─ReLU: 3-52                             --\n",
            "│    └─Dropout: 2-30                               --\n",
            "├─Sequential: 1-8                                  --\n",
            "│    └─Linear: 2-31                                16,448\n",
            "│    └─BatchNorm1d: 2-32                           128\n",
            "│    └─ReLU: 2-33                                  --\n",
            "│    └─Linear: 2-34                                2,080\n",
            "│    └─BatchNorm1d: 2-35                           64\n",
            "│    └─ReLU: 2-36                                  --\n",
            "│    └─Linear: 2-37                                627\n",
            "===========================================================================\n",
            "Total params: 1,243,251\n",
            "Trainable params: 1,219,187\n",
            "Non-trainable params: 24,064\n",
            "===========================================================================\n",
            "Summary of the model_AfterFreez1:  ===========================================================================\n",
            "Layer (type:depth-idx)                             Param #\n",
            "===========================================================================\n",
            "PseTae                                             --\n",
            "├─PixelSetEncoder: 1-1                             --\n",
            "│    └─Sequential: 2-1                             --\n",
            "│    │    └─linlayer: 3-1                          (480)\n",
            "│    │    └─linlayer: 3-2                          (2,240)\n",
            "│    └─Sequential: 2-2                             --\n",
            "│    │    └─Linear: 3-3                            (17,024)\n",
            "│    │    └─BatchNorm1d: 3-4                       (256)\n",
            "├─TemporalAttentionEncoder: 1-2                    --\n",
            "│    └─Embedding: 2-3                              (3,584)\n",
            "│    └─LayerNorm: 2-4                              256\n",
            "│    └─LayerNorm: 2-5                              256\n",
            "│    └─MultiHeadAttention: 2-6                     --\n",
            "│    │    └─Linear: 3-5                            16,512\n",
            "│    │    └─Linear: 3-6                            16,512\n",
            "│    │    └─Sequential: 3-7                        16,768\n",
            "│    │    └─ScaledDotProductAttention: 3-8         --\n",
            "│    └─Sequential: 2-7                             --\n",
            "│    │    └─Linear: 3-9                            65,664\n",
            "│    │    └─BatchNorm1d: 3-10                      256\n",
            "│    │    └─ReLU: 3-11                             --\n",
            "│    │    └─Linear: 3-12                           16,512\n",
            "│    │    └─BatchNorm1d: 3-13                      256\n",
            "│    │    └─ReLU: 3-14                             --\n",
            "│    └─Dropout: 2-8                                --\n",
            "├─PixelSetEncoder: 1-3                             --\n",
            "│    └─Sequential: 2-9                             --\n",
            "│    │    └─linlayer: 3-15                         416\n",
            "│    │    └─linlayer: 3-16                         2,240\n",
            "│    └─Sequential: 2-10                            --\n",
            "│    │    └─Linear: 3-17                           17,024\n",
            "│    │    └─BatchNorm1d: 3-18                      256\n",
            "├─PixelSetEncoder: 1-4                             --\n",
            "│    └─Sequential: 2-11                            --\n",
            "│    │    └─linlayer: 3-19                         160\n",
            "│    │    └─linlayer: 3-20                         2,240\n",
            "│    └─Sequential: 2-12                            --\n",
            "│    │    └─Linear: 3-21                           17,024\n",
            "│    │    └─BatchNorm1d: 3-22                      256\n",
            "├─TemporalAttentionEncoder: 1-5                    --\n",
            "│    └─Embedding: 2-13                             (7,168)\n",
            "│    └─LayerNorm: 2-14                             512\n",
            "│    └─LayerNorm: 2-15                             512\n",
            "│    └─MultiHeadAttention: 2-16                    --\n",
            "│    │    └─Linear: 3-23                           32,896\n",
            "│    │    └─Linear: 3-24                           32,896\n",
            "│    │    └─Sequential: 3-25                       16,768\n",
            "│    │    └─ScaledDotProductAttention: 3-26        --\n",
            "│    └─Sequential: 2-17                            --\n",
            "│    │    └─Linear: 3-27                           524,800\n",
            "│    │    └─BatchNorm1d: 3-28                      1,024\n",
            "│    │    └─ReLU: 3-29                             --\n",
            "│    │    └─Linear: 3-30                           131,328\n",
            "│    │    └─BatchNorm1d: 3-31                      512\n",
            "│    │    └─ReLU: 3-32                             --\n",
            "│    └─Dropout: 2-18                               --\n",
            "├─TemporalAttentionEncoder: 1-6                    --\n",
            "│    └─Embedding: 2-19                             (3,584)\n",
            "│    └─LayerNorm: 2-20                             256\n",
            "│    └─LayerNorm: 2-21                             256\n",
            "│    └─MultiHeadAttention: 2-22                    --\n",
            "│    │    └─Linear: 3-33                           16,512\n",
            "│    │    └─Linear: 3-34                           16,512\n",
            "│    │    └─Sequential: 3-35                       16,768\n",
            "│    │    └─ScaledDotProductAttention: 3-36        --\n",
            "│    └─Sequential: 2-23                            --\n",
            "│    │    └─Linear: 3-37                           65,664\n",
            "│    │    └─BatchNorm1d: 3-38                      256\n",
            "│    │    └─ReLU: 3-39                             --\n",
            "│    │    └─Linear: 3-40                           16,512\n",
            "│    │    └─BatchNorm1d: 3-41                      256\n",
            "│    │    └─ReLU: 3-42                             --\n",
            "│    └─Dropout: 2-24                               --\n",
            "├─TemporalAttentionEncoder: 1-7                    --\n",
            "│    └─Embedding: 2-25                             (9,728)\n",
            "│    └─LayerNorm: 2-26                             256\n",
            "│    └─LayerNorm: 2-27                             256\n",
            "│    └─MultiHeadAttention: 2-28                    --\n",
            "│    │    └─Linear: 3-43                           16,512\n",
            "│    │    └─Linear: 3-44                           16,512\n",
            "│    │    └─Sequential: 3-45                       16,768\n",
            "│    │    └─ScaledDotProductAttention: 3-46        --\n",
            "│    └─Sequential: 2-29                            --\n",
            "│    │    └─Linear: 3-47                           65,664\n",
            "│    │    └─BatchNorm1d: 3-48                      256\n",
            "│    │    └─ReLU: 3-49                             --\n",
            "│    │    └─Linear: 3-50                           16,512\n",
            "│    │    └─BatchNorm1d: 3-51                      256\n",
            "│    │    └─ReLU: 3-52                             --\n",
            "│    └─Dropout: 2-30                               --\n",
            "├─Sequential: 1-8                                  --\n",
            "│    └─Linear: 2-31                                16,448\n",
            "│    └─BatchNorm1d: 2-32                           128\n",
            "│    └─ReLU: 2-33                                  --\n",
            "│    └─Linear: 2-34                                2,080\n",
            "│    └─BatchNorm1d: 2-35                           64\n",
            "│    └─ReLU: 2-36                                  --\n",
            "│    └─Linear: 2-37                                627\n",
            "===========================================================================\n",
            "Total params: 1,243,251\n",
            "Trainable params: 1,199,187\n",
            "Non-trainable params: 44,064\n",
            "===========================================================================\n",
            "Summary of the model_AfterFreez2:  ===========================================================================\n",
            "Layer (type:depth-idx)                             Param #\n",
            "===========================================================================\n",
            "PseTae                                             --\n",
            "├─PixelSetEncoder: 1-1                             --\n",
            "│    └─Sequential: 2-1                             --\n",
            "│    │    └─linlayer: 3-1                          (480)\n",
            "│    │    └─linlayer: 3-2                          (2,240)\n",
            "│    └─Sequential: 2-2                             --\n",
            "│    │    └─Linear: 3-3                            (17,024)\n",
            "│    │    └─BatchNorm1d: 3-4                       (256)\n",
            "├─TemporalAttentionEncoder: 1-2                    --\n",
            "│    └─Embedding: 2-3                              (3,584)\n",
            "│    └─LayerNorm: 2-4                              (256)\n",
            "│    └─LayerNorm: 2-5                              (256)\n",
            "│    └─MultiHeadAttention: 2-6                     --\n",
            "│    │    └─Linear: 3-5                            (16,512)\n",
            "│    │    └─Linear: 3-6                            (16,512)\n",
            "│    │    └─Sequential: 3-7                        (16,768)\n",
            "│    │    └─ScaledDotProductAttention: 3-8         --\n",
            "│    └─Sequential: 2-7                             --\n",
            "│    │    └─Linear: 3-9                            (65,664)\n",
            "│    │    └─BatchNorm1d: 3-10                      (256)\n",
            "│    │    └─ReLU: 3-11                             --\n",
            "│    │    └─Linear: 3-12                           (16,512)\n",
            "│    │    └─BatchNorm1d: 3-13                      (256)\n",
            "│    │    └─ReLU: 3-14                             --\n",
            "│    └─Dropout: 2-8                                --\n",
            "├─PixelSetEncoder: 1-3                             --\n",
            "│    └─Sequential: 2-9                             --\n",
            "│    │    └─linlayer: 3-15                         416\n",
            "│    │    └─linlayer: 3-16                         2,240\n",
            "│    └─Sequential: 2-10                            --\n",
            "│    │    └─Linear: 3-17                           17,024\n",
            "│    │    └─BatchNorm1d: 3-18                      256\n",
            "├─PixelSetEncoder: 1-4                             --\n",
            "│    └─Sequential: 2-11                            --\n",
            "│    │    └─linlayer: 3-19                         160\n",
            "│    │    └─linlayer: 3-20                         2,240\n",
            "│    └─Sequential: 2-12                            --\n",
            "│    │    └─Linear: 3-21                           17,024\n",
            "│    │    └─BatchNorm1d: 3-22                      256\n",
            "├─TemporalAttentionEncoder: 1-5                    --\n",
            "│    └─Embedding: 2-13                             (7,168)\n",
            "│    └─LayerNorm: 2-14                             512\n",
            "│    └─LayerNorm: 2-15                             512\n",
            "│    └─MultiHeadAttention: 2-16                    --\n",
            "│    │    └─Linear: 3-23                           32,896\n",
            "│    │    └─Linear: 3-24                           32,896\n",
            "│    │    └─Sequential: 3-25                       16,768\n",
            "│    │    └─ScaledDotProductAttention: 3-26        --\n",
            "│    └─Sequential: 2-17                            --\n",
            "│    │    └─Linear: 3-27                           524,800\n",
            "│    │    └─BatchNorm1d: 3-28                      1,024\n",
            "│    │    └─ReLU: 3-29                             --\n",
            "│    │    └─Linear: 3-30                           131,328\n",
            "│    │    └─BatchNorm1d: 3-31                      512\n",
            "│    │    └─ReLU: 3-32                             --\n",
            "│    └─Dropout: 2-18                               --\n",
            "├─TemporalAttentionEncoder: 1-6                    --\n",
            "│    └─Embedding: 2-19                             (3,584)\n",
            "│    └─LayerNorm: 2-20                             256\n",
            "│    └─LayerNorm: 2-21                             256\n",
            "│    └─MultiHeadAttention: 2-22                    --\n",
            "│    │    └─Linear: 3-33                           16,512\n",
            "│    │    └─Linear: 3-34                           16,512\n",
            "│    │    └─Sequential: 3-35                       16,768\n",
            "│    │    └─ScaledDotProductAttention: 3-36        --\n",
            "│    └─Sequential: 2-23                            --\n",
            "│    │    └─Linear: 3-37                           65,664\n",
            "│    │    └─BatchNorm1d: 3-38                      256\n",
            "│    │    └─ReLU: 3-39                             --\n",
            "│    │    └─Linear: 3-40                           16,512\n",
            "│    │    └─BatchNorm1d: 3-41                      256\n",
            "│    │    └─ReLU: 3-42                             --\n",
            "│    └─Dropout: 2-24                               --\n",
            "├─TemporalAttentionEncoder: 1-7                    --\n",
            "│    └─Embedding: 2-25                             (9,728)\n",
            "│    └─LayerNorm: 2-26                             256\n",
            "│    └─LayerNorm: 2-27                             256\n",
            "│    └─MultiHeadAttention: 2-28                    --\n",
            "│    │    └─Linear: 3-43                           16,512\n",
            "│    │    └─Linear: 3-44                           16,512\n",
            "│    │    └─Sequential: 3-45                       16,768\n",
            "│    │    └─ScaledDotProductAttention: 3-46        --\n",
            "│    └─Sequential: 2-29                            --\n",
            "│    │    └─Linear: 3-47                           65,664\n",
            "│    │    └─BatchNorm1d: 3-48                      256\n",
            "│    │    └─ReLU: 3-49                             --\n",
            "│    │    └─Linear: 3-50                           16,512\n",
            "│    │    └─BatchNorm1d: 3-51                      256\n",
            "│    │    └─ReLU: 3-52                             --\n",
            "│    └─Dropout: 2-30                               --\n",
            "├─Sequential: 1-8                                  --\n",
            "│    └─Linear: 2-31                                16,448\n",
            "│    └─BatchNorm1d: 2-32                           128\n",
            "│    └─ReLU: 2-33                                  --\n",
            "│    └─Linear: 2-34                                2,080\n",
            "│    └─BatchNorm1d: 2-35                           64\n",
            "│    └─ReLU: 2-36                                  --\n",
            "│    └─Linear: 2-37                                627\n",
            "===========================================================================\n",
            "Total params: 1,243,251\n",
            "Trainable params: 1,066,195\n",
            "Non-trainable params: 177,056\n",
            "===========================================================================\n",
            "TOTAL TRAINABLE PARAMETERS : 324947\n",
            "RATIOS: Spatial  12.2% , Temporal  81.9% , Classifier   6.0%\n",
            "None\n",
            "EPOCH 1/3\n",
            "train epoch complete in -----------------------> 0:00:00.433839\n",
            "Validation . . . \n",
            "Loss 2.1179,  Acc 43.88,  IoU 0.0896\n",
            "EPOCH 2/3\n",
            "train epoch complete in -----------------------> 0:00:00.444588\n",
            "Validation . . . \n",
            "Loss 2.1906,  Acc 40.82,  IoU 0.0742\n",
            "EPOCH 3/3\n",
            "train epoch complete in -----------------------> 0:00:00.459616\n",
            "Validation . . . \n",
            "Loss 2.1193,  Acc 41.84,  IoU 0.0765\n",
            "Testing best epoch . . .\n",
            "Loss 2.1377,  Acc 43.88,  IoU 0.1463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/learning/metrics.py:60: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  d['IoU'] = tp / (tp + fp + fn)\n",
            "/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/learning/metrics.py:61: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  d['Precision'] = tp / (tp + fp)\n",
            "/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/learning/metrics.py:62: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  d['Recall'] = tp / (tp + fn)\n",
            "/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/learning/metrics.py:63: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  d['F1-score'] = 2 * tp / (2 * tp + fp + fn)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall performance:\n",
            "Acc: 0.4387755102040816,  IoU: 0.14625850340136054\n",
            "total elapsed time is ---> 0:00:15.836036\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# %%\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start = datetime.now()\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    #/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/dataset_folder/s1_data\n",
        "    #/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/test_folder/s1_data\n",
        "    #/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/val_folder/s1_data\n",
        "    \n",
        "\n",
        "\n",
        "    # Set-up parameters\n",
        "    parser.add_argument('--dataset_folder', default='/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/dataset_folder/s1_data', type=str,\n",
        "                        help='Path to the folder where the results are saved.')\n",
        "\n",
        "    # set-up data loader folders -----------------------------\n",
        "    parser.add_argument('--dataset_folder2', default=None, type=str,\n",
        "                        help='Path to second train folder to concat with first initial loader.')\n",
        "    parser.add_argument('--val_folder', default='/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/val_folder/s1_data', type=str,\n",
        "                        help='Path to the validation folder.')\n",
        "    parser.add_argument('--test_folder', default='/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/test_folder/s1_data', type=str,\n",
        "                        help='Path to the test folder.')\n",
        "\n",
        "    # ---------------------------add sensor argument to test s1/s2\n",
        "    parser.add_argument('--minimum_sampling', default=None, type=int,\n",
        "                        help='minimum time series length to sample')      \n",
        "    parser.add_argument('--fusion_type', default='tsa', type=str,\n",
        "                        help='level of multi-sensor fusion e.g. early, pse, tsa, softmax_avg, softmax_norm')\n",
        "    parser.add_argument('--interpolate_method', default='nn', type=str,\n",
        "                        help='type of interpolation for early and pse fusion. eg. \"nn\",\"linear\"')    \n",
        "    \n",
        "    parser.add_argument('--res_dir', default='./results_TL', help='Path to the folder where the results should be stored')\n",
        "    parser.add_argument('--res_dir_WE', default='./results_WE', help='Path to the folder where the results should be stored')\n",
        "    parser.add_argument('--num_workers', default=8, type=int, help='Number of data loading workers')\n",
        "    parser.add_argument('--rdm_seed', default=1, type=int, help='Random seed')\n",
        "    parser.add_argument('--device', default='cuda', type=str,\n",
        "                        help='Name of device to use for tensor computations (cuda/cpu)')\n",
        "    parser.add_argument('--display_step', default=50, type=int,\n",
        "                        help='Interval in batches between display of training metrics')\n",
        "    parser.add_argument('--preload', dest='preload', action='store_true',\n",
        "                        help='If specified, the whole dataset is loaded to RAM at initialization')\n",
        "    parser.set_defaults(preload=False)\n",
        "\n",
        "    # Training parameters\n",
        "    parser.add_argument('--epochs', default=3, type=int, help='Number of epochs per fold')\n",
        "    parser.add_argument('--batch_size', default=32, type=int, help='Batch size')\n",
        "    parser.add_argument('--lr', default=0.001, type=float, help='Learning rate')\n",
        "    parser.add_argument('--gamma', default=1, type=float, help='Gamma parameter of the focal loss')\n",
        "    parser.add_argument('--npixel', default=5, type=int, help='Number of pixels to sample from the input images')\n",
        "\n",
        "    # Architecture Hyperparameters\n",
        "    ## PSE\n",
        "    parser.add_argument('--input_dim', default=10, type=int, help='Number of channels of input images')\n",
        "    parser.add_argument('--mlp1', default='[10,32,64]', type=str, help='Number of neurons in the layers of MLP1')\n",
        "    parser.add_argument('--pooling', default='mean_std', type=str, help='Pixel-embeddings pooling strategy')\n",
        "    parser.add_argument('--mlp2', default='[132,128]', type=str, help='Number of neurons in the layers of MLP2')\n",
        "    parser.add_argument('--geomfeat', default=1, type=int,\n",
        "                        help='If 1 the precomputed geometrical features (f) are used in the PSE.')\n",
        " ## TAE\n",
        "    parser.add_argument('--n_head', default=4, type=int, help='Number of attention heads')\n",
        "    parser.add_argument('--d_k', default=32, type=int, help='Dimension of the key and query vectors')\n",
        "    parser.add_argument('--mlp3', default='[512,128,128]', type=str, help='Number of neurons in the layers of MLP3')\n",
        "    parser.add_argument('--T', default=1000, type=int, help='Maximum period for the positional encoding')\n",
        "    parser.add_argument('--positions', default='bespoke', type=str,\n",
        "                        help='Positions to use for the positional encoding (bespoke / order)')\n",
        "    parser.add_argument('--lms', default=None, type=int,\n",
        "                        help='Maximum sequence length for positional encoding (only necessary if positions == order)')\n",
        "    parser.add_argument('--dropout', default=0.2, type=float, help='Dropout probability')\n",
        "\n",
        "    ## Classifier\n",
        "    parser.add_argument('--num_classes', default=19, type=int, help='Number of classes')\n",
        "    parser.add_argument('--mlp4', default='[256, 64, 32, 19]', type=str, help='Number of neurons in the layers of MLP4- pse and tae nedd 256 except 128')\n",
        "\n",
        "    args= parser.parse_args(args=[])\n",
        "    args= vars(args)\n",
        "    for k, v in args.items():\n",
        "            if 'mlp' in k:\n",
        "                v = v.replace('[', '')\n",
        "                v = v.replace(']', '')\n",
        "                args[k] = list(map(int, v.split(',')))\n",
        "\n",
        "    pprint.pprint(args)\n",
        "    main(args)\n",
        "\n",
        "\n",
        "    #add processing time\n",
        "    print('total elapsed time is --->', datetime.now() -start)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
