{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchnet as tnt\n",
        "# from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import os\n",
        "import json\n",
        "import pickle as pkl\n",
        "import argparse\n",
        "import pprint\n",
        "from datetime import datetime\n",
        "\n",
        "from models.stclassifier_fusion import PseTae\n",
        "from dataset_fusion import PixelSetData, PixelSetData_preloaded\n",
        "from learning.focal_loss import FocalLoss\n",
        "from learning.weight_init import weight_init\n",
        "from learning.metrics import mIou, confusion_matrix_analysis\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.12.1+cu116'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def train_epoch(model, optimizer, criterion, data_loader, device, args):\n",
        "    start = datetime.now()\n",
        "    acc_meter = tnt.meter.ClassErrorMeter(accuracy=True)\n",
        "    loss_meter = tnt.meter.AverageValueMeter()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for i, (x, x2, y, dates) in enumerate(data_loader): \n",
        "                \n",
        "        y_true.extend(list(map(int, y)))\n",
        "\n",
        "        x = recursive_todevice(x, device)\n",
        "        x2 = recursive_todevice(x2, device) \n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x, x2, dates)\n",
        "        loss = criterion(out, y.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = out.detach()\n",
        "        y_p = pred.argmax(dim=1).cpu().numpy()\n",
        "        y_pred.extend(list(y_p))\n",
        "        acc_meter.add(pred, y)\n",
        "        loss_meter.add(loss.item())\n",
        "\n",
        "        if (i + 1) % args['display_step'] == 0:\n",
        "            print('Step [{}/{}], Loss: {:.4f}, Acc : {:.2f}'.format(i + 1, len(data_loader), loss_meter.value()[0],\n",
        "                                                                    acc_meter.value()[0]))\n",
        "\n",
        "    epoch_metrics = {'train_loss': loss_meter.value()[0],\n",
        "                     'train_accuracy': acc_meter.value()[0],\n",
        "                     'train_IoU': mIou(y_true, y_pred, n_classes=args['num_classes'])}\n",
        "    print('train epoch complete in ----------------------->', datetime.now()-start)\n",
        "    return epoch_metrics\n",
        "\n",
        "\n",
        "def evaluation(model, criterion, loader, device, args, mode='val'):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    acc_meter = tnt.meter.ClassErrorMeter(accuracy=True)\n",
        "    loss_meter = tnt.meter.AverageValueMeter()\n",
        "\n",
        "    for (x, x2, y, dates) in loader: \n",
        "\n",
        "        y_true.extend(list(map(int, y)))\n",
        "\n",
        "        x = recursive_todevice(x, device)\n",
        "        x2 = recursive_todevice(x2, device) #add x2 to device\n",
        "        y = y.to(device)\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prediction = model(x, x2, dates)  \n",
        "            loss = criterion(prediction, y)\n",
        "\n",
        "        acc_meter.add(prediction, y)\n",
        "        loss_meter.add(loss.item())\n",
        "\n",
        "        y_p = prediction.argmax(dim=1).cpu().numpy()\n",
        "        y_pred.extend(list(y_p))\n",
        "\n",
        "    metrics = {'{}_accuracy'.format(mode): acc_meter.value()[0],\n",
        "               '{}_loss'.format(mode): loss_meter.value()[0],\n",
        "               '{}_IoU'.format(mode): mIou(y_true, y_pred, args['num_classes'])}\n",
        "\n",
        "    if mode == 'val':\n",
        "        return metrics\n",
        "    elif mode == 'test':\n",
        "        return metrics, confusion_matrix(y_true, y_pred, labels=list(range(args['num_classes']))), y_true, y_pred \n",
        "\n",
        "\n",
        "def get_pse(folder, args):\n",
        "    if args['preload']:\n",
        "        dt = PixelSetData_preloaded(args[folder], labels='label_19class', npixel=args['npixel'],\n",
        "                          sub_classes = None,\n",
        "                          norm=None,\n",
        "                          minimum_sampling=args['minimum_sampling'],\n",
        "                          fusion_type = args['fusion_type'], interpolate_method = args['interpolate_method'],\n",
        "                          extra_feature='geomfeat' if args['geomfeat'] else None,  \n",
        "                          jitter=None)\n",
        "    else:\n",
        "        dt = PixelSetData(args[folder], labels='label_19class', npixel=args['npixel'],\n",
        "                          sub_classes = None,\n",
        "                          norm=None,\n",
        "                          minimum_sampling=args['minimum_sampling'],\n",
        "                          fusion_type = args['fusion_type'], interpolate_method = args['interpolate_method'],\n",
        "                          extra_feature='geomfeat' if args['geomfeat'] else None,  \n",
        "                          jitter=None)\n",
        "    return dt\n",
        "\n",
        "def get_loaders(args):\n",
        "    loader_seq =[]\n",
        "    train_dataset = get_pse('dataset_folder', args)\n",
        "    val_dataset = get_pse('val_folder', args)\n",
        "    test_dataset = get_pse('test_folder', args)\n",
        "\n",
        "    if args['dataset_folder2'] is not None:\n",
        "        train_dataset2 = get_pse('dataset_folder2', args)\n",
        "        train_dataset = data.ConcatDataset([train_dataset, train_dataset2])\n",
        "\n",
        "        \n",
        "    train_loader = data.DataLoader(train_dataset, batch_size=args['batch_size'],\n",
        "                                        num_workers=args['num_workers'], shuffle = True, pin_memory =True) \n",
        "\n",
        "    validation_loader = data.DataLoader(val_dataset, batch_size=args['batch_size'],\n",
        "                                        num_workers=args['num_workers'], shuffle = False, pin_memory = True)\n",
        "\n",
        "    test_loader = data.DataLoader(test_dataset, batch_size=args['batch_size'],\n",
        "                                    num_workers=args['num_workers'], shuffle = False, pin_memory =True)\n",
        "\n",
        "    loader_seq.append((train_loader, validation_loader, test_loader))\n",
        "    return loader_seq\n",
        "\n",
        "def recursive_todevice(x, device):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x.to(device)\n",
        "    else:\n",
        "        return [recursive_todevice(c, device) for c in x]\n",
        "\n",
        "\n",
        "def prepare_output(args):\n",
        "    os.makedirs(args['res_dir'], exist_ok=True)\n",
        "\n",
        "\n",
        "def checkpoint(log, args):\n",
        "    with open(os.path.join(args['res_dir'], 'trainlog.json'), 'w') as outfile:\n",
        "        json.dump(log, outfile, indent=4)\n",
        "\n",
        "\n",
        "def save_results(metrics, conf_mat, args, y_true, y_pred):\n",
        "    with open(os.path.join(args['res_dir'], 'test_metrics.json'), 'w') as outfile:\n",
        "        json.dump(metrics, outfile, indent=4)\n",
        "    pkl.dump(conf_mat, open(os.path.join(args['res_dir'], 'conf_mat.pkl'), 'wb'))\n",
        "\n",
        "\n",
        "    # save y_true, y_pred\n",
        "    pkl.dump(y_true, open(os.path.join(args['res_dir'], 'y_true_test_data.pkl'), 'wb'))\n",
        "    pkl.dump(y_pred, open(os.path.join(args['res_dir'], 'y_pred_test_data.pkl'), 'wb'))\n",
        "\n",
        "    # ----> save confusion matrix \n",
        "    plt.figure(figsize=(15,10))\n",
        "    img = sns.heatmap(conf_mat, annot = True, fmt='d',linewidths=0.5, cmap='OrRd')\n",
        "    img.tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
        "    img.set(ylabel=\"True Label\", xlabel=\"Predicted Label\")\n",
        "    img.figure.savefig(os.path.join(args['res_dir'], 'conf_mat_picture.png'))\n",
        "    img.get_figure().clf()\n",
        "\n",
        "\n",
        "def overall_performance(args):\n",
        "    cm = np.zeros((args['num_classes'], args['num_classes']))\n",
        "    cm += pkl.load(open(os.path.join(args['res_dir'], 'conf_mat.pkl'), 'rb'))\n",
        "    per_class, perf = confusion_matrix_analysis(cm)\n",
        "\n",
        "    print('Overall performance:')\n",
        "    print('Acc: {},  IoU: {}'.format(perf['Accuracy'], perf['MACRO_IoU']))\n",
        "\n",
        "    with open(os.path.join(args['res_dir'], 'overall.json'), 'w') as file:\n",
        "        file.write(json.dumps(perf, indent=4))\n",
        "    with open(os.path.join(args['res_dir'], 'per_class.json'), 'w') as file:\n",
        "        file.write(json.dumps(per_class, indent=4))\n",
        "\n",
        "\n",
        "def plot_metrics(args):\n",
        "    with open(os.path.join(args['res_dir'], 'trainlog.json'), 'r') as file:\n",
        "        d = json.loads(file.read())\n",
        "    \n",
        "    epoch = [i+1 for i in range(len(d))]\n",
        "    train_loss = [d[str(i+1)][\"train_loss\"] for i in range(len(d))]\n",
        "    val_loss = [d[str(i+1)][\"val_loss\"] for i in range(len(d))]\n",
        "    train_acc = [d[str(i+1)][\"train_accuracy\"] for i in range(len(d))]\n",
        "    val_acc = [d[str(i+1)][\"val_accuracy\"] for i in range(len(d))]\n",
        "\n",
        "    # plot loss/accuracy\n",
        "    plt.title('monitoring metrics - loss')\n",
        "    plt.plot(epoch, train_loss, label = \"train_loss\")\n",
        "    plt.plot(epoch,val_loss, label = \"val_loss\")\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(args['res_dir'], 'loss_graph.png'))\n",
        "    plt.clf()\n",
        "\n",
        "    plt.title('monitoring metrics - accuracy')\n",
        "    plt.plot(epoch, train_acc, label = \"train_accuracy\")\n",
        "    plt.plot(epoch,val_acc, label = \"val_accuracy\")\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(args['res_dir'], 'accuracy_graph.png'))\n",
        "    plt.clf()\n",
        "    #---------------------------------------------\n",
        "\n",
        "def main(args):\n",
        "    np.random.seed(args['rdm_seed'])\n",
        "    torch.manual_seed(args['rdm_seed'])\n",
        "    prepare_output(args)\n",
        "\n",
        "    extra = 'geomfeat' if args['geomfeat'] else None\n",
        "\n",
        "    device = torch.device(args['device'])\n",
        "\n",
        "    loaders = get_loaders(args)\n",
        "    for _, (train_loader, val_loader, test_loader) in enumerate(loaders):\n",
        "        print('Train {}, Val {}, Test {}'.format(len(train_loader), len(val_loader), len(test_loader)))\n",
        "\n",
        "        model_args = dict(input_dim=args['input_dim'], mlp1=args['mlp1'], pooling=args['pooling'],\n",
        "                            mlp2=args['mlp2'], n_head=args['n_head'], d_k=args['d_k'], mlp3=args['mlp3'],\n",
        "                            dropout=args['dropout'], T=args['T'], len_max_seq=args['lms'],\n",
        "                            positions=None, fusion_type = args['fusion_type'],\n",
        "                            mlp4=args['mlp4'])\n",
        "\n",
        "        if args['geomfeat']:\n",
        "            model_args.update(with_extra=True, extra_size=4) \n",
        "        else:\n",
        "            model_args.update(with_extra=False, extra_size=None)\n",
        "\n",
        "        model = PseTae(**model_args)\n",
        "\n",
        "        print(model.param_ratio())\n",
        "\n",
        "\n",
        "        model = model.to(device)\n",
        "        model.apply(weight_init)\n",
        "        optimizer = torch.optim.Adam(model.parameters())\n",
        "        criterion = FocalLoss(args['gamma'])\n",
        "\n",
        "        trainlog = {}\n",
        "\n",
        "\n",
        "        best_mIoU = 0\n",
        "        for epoch in range(1, args['epochs'] + 1):\n",
        "            print('EPOCH {}/{}'.format(epoch, args['epochs']))\n",
        "\n",
        "            model.train()\n",
        "            train_metrics = train_epoch(model, optimizer, criterion, train_loader, device=device, args=args)\n",
        "\n",
        "            print('Validation . . . ')\n",
        "            model.eval()\n",
        "            val_metrics = evaluation(model, criterion, val_loader, device=device, args=args, mode='val')\n",
        "\n",
        "            print('Loss {:.4f},  Acc {:.2f},  IoU {:.4f}'.format(val_metrics['val_loss'], val_metrics['val_accuracy'],\n",
        "                                                                 val_metrics['val_IoU']))\n",
        "\n",
        "            trainlog[epoch] = {**train_metrics, **val_metrics}\n",
        "            checkpoint(trainlog, args)\n",
        "\n",
        "            if val_metrics['val_IoU'] >= best_mIoU:\n",
        "                best_mIoU = val_metrics['val_IoU']\n",
        "                torch.save({'epoch': epoch, 'state_dict': model.state_dict(),\n",
        "                            'optimizer': optimizer.state_dict()},\n",
        "                           os.path.join(args['res_dir'], 'model.pth.tar'))\n",
        "\n",
        "        print('Testing best epoch . . .')\n",
        "        model.load_state_dict(\n",
        "            torch.load(os.path.join(args['res_dir'],  'model.pth.tar'))['state_dict'])\n",
        "        model.eval()\n",
        "\n",
        "        test_metrics, conf_mat, y_true, y_pred = evaluation(model, criterion, test_loader, device=device, mode='test', args=args) \n",
        "\n",
        "        print('Loss {:.4f},  Acc {:.2f},  IoU {:.4f}'.format(test_metrics['test_loss'], test_metrics['test_accuracy'],\n",
        "                                                             test_metrics['test_IoU']))\n",
        "                                                             \n",
        "        save_results(test_metrics, conf_mat, args, y_true, y_pred) \n",
        "\n",
        "    overall_performance(args)\n",
        "    plot_metrics(args)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'T': 1000,\n",
            " 'batch_size': 16,\n",
            " 'd_k': 32,\n",
            " 'dataset_folder': '/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/dataset_folder/s1_data',\n",
            " 'dataset_folder2': None,\n",
            " 'device': 'cuda',\n",
            " 'display_step': 50,\n",
            " 'dropout': 0.2,\n",
            " 'epochs': 3,\n",
            " 'fusion_type': 'early',\n",
            " 'gamma': 1,\n",
            " 'geomfeat': 1,\n",
            " 'input_dim': 10,\n",
            " 'interpolate_method': 'nn',\n",
            " 'lms': None,\n",
            " 'lr': 0.001,\n",
            " 'minimum_sampling': None,\n",
            " 'mlp1': [10, 32, 64],\n",
            " 'mlp2': [128, 128],\n",
            " 'mlp3': [512, 128, 128],\n",
            " 'mlp4': [128, 64, 32, 19],\n",
            " 'n_head': 4,\n",
            " 'npixel': 5,\n",
            " 'num_classes': 19,\n",
            " 'num_workers': 8,\n",
            " 'pooling': 'mean_std',\n",
            " 'positions': 'bespoke',\n",
            " 'preload': False,\n",
            " 'rdm_seed': 1,\n",
            " 'res_dir': './results',\n",
            " 'test_folder': '/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/test_folder/s1_data',\n",
            " 'val_folder': '/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/val_folder/s1_data'}\n",
            "Train 7, Val 7, Test 7\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m             args[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, v\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m     81\u001b[0m pprint\u001b[38;5;241m.\u001b[39mpprint(args)\n\u001b[0;32m---> 82\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m#add processing time\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal elapsed time is --->\u001b[39m\u001b[38;5;124m'\u001b[39m, datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39mstart)\n",
            "Cell \u001b[0;32mIn[7], line 218\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     model_args\u001b[38;5;241m.\u001b[39mupdate(with_extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, extra_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 218\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPseTae\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mparam_ratio())\n\u001b[1;32m    223\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n",
            "File \u001b[0;32m~/shakouri/CropTypeMappinp/multi_sensor/models/stclassifier_fusion.py:36\u001b[0m, in \u001b[0;36mPseTae.__init__\u001b[0;34m(self, input_dim, mlp1, pooling, mlp2, with_extra, extra_size, n_head, d_k, d_model, mlp3, dropout, T, len_max_seq, positions, mlp4, fusion_type)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositions \u001b[38;5;241m=\u001b[39m positions \n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# ----------------early fusion        \u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspatial_encoder_earlyFusion \u001b[38;5;241m=\u001b[39m \u001b[43mPixelSetEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_seq_mlp1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_seq_mlp1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlp2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_extra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_extra\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_size\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporal_encoder_earlyFusion \u001b[38;5;241m=\u001b[39m TemporalAttentionEncoder(in_channels\u001b[38;5;241m=\u001b[39mmlp2[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], n_head\u001b[38;5;241m=\u001b[39mn_head, d_k\u001b[38;5;241m=\u001b[39md_k, d_model\u001b[38;5;241m=\u001b[39md_model,\n\u001b[1;32m     40\u001b[0m                                                  n_neurons\u001b[38;5;241m=\u001b[39mmlp3, dropout\u001b[38;5;241m=\u001b[39mdropout,\n\u001b[1;32m     41\u001b[0m                                                 T\u001b[38;5;241m=\u001b[39mT, len_max_seq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms2_max_len, positions\u001b[38;5;241m=\u001b[39mpositions)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# ----------------pse fusion\u001b[39;00m\n",
            "File \u001b[0;32m~/shakouri/CropTypeMappinp/multi_sensor/models/pse_fusion.py:48\u001b[0m, in \u001b[0;36mPixelSetEncoder.__init__\u001b[0;34m(self, input_dim, mlp1, pooling, mlp2, with_extra, extra_size)\u001b[0m\n\u001b[1;32m     45\u001b[0m     inter_dim \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_size\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (input_dim \u001b[38;5;241m==\u001b[39m mlp1[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (inter_dim \u001b[38;5;241m==\u001b[39m mlp2[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Feature extraction\u001b[39;00m\n\u001b[1;32m     51\u001b[0m layers \u001b[38;5;241m=\u001b[39m []\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    start = datetime.now()\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    #/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/dataset_folder/s1_data\n",
        "    #/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/test_folder/s1_data\n",
        "    #/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/val_folder/s1_data\n",
        "    \n",
        "\n",
        "\n",
        "    # Set-up parameters\n",
        "    parser.add_argument('--dataset_folder', default='/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/dataset_folder/s1_data', type=str,\n",
        "                        help='Path to the folder where the results are saved.')\n",
        "\n",
        "    # set-up data loader folders -----------------------------\n",
        "    parser.add_argument('--dataset_folder2', default=None, type=str,\n",
        "                        help='Path to second train folder to concat with first initial loader.')\n",
        "    parser.add_argument('--val_folder', default='/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/val_folder/s1_data', type=str,\n",
        "                        help='Path to the validation folder.')\n",
        "    parser.add_argument('--test_folder', default='/home/mhbokaei/shakouri/CropTypeMappinp/multi_sensor/All_dataset/dataset_100/test_folder/s1_data', type=str,\n",
        "                        help='Path to the test folder.')\n",
        "\n",
        "    # ---------------------------add sensor argument to test s1/s2\n",
        "    parser.add_argument('--minimum_sampling', default=None, type=int,\n",
        "                        help='minimum time series length to sample')      \n",
        "    parser.add_argument('--fusion_type', default='early', type=str,\n",
        "                        help='level of multi-sensor fusion e.g. early, pse, tsa, softmax_avg, softmax_norm')\n",
        "    parser.add_argument('--interpolate_method', default='nn', type=str,\n",
        "                        help='type of interpolation for early and pse fusion. eg. \"nn\",\"linear\"')    \n",
        "    \n",
        "    parser.add_argument('--res_dir', default='./results', help='Path to the folder where the results should be stored')\n",
        "    parser.add_argument('--num_workers', default=8, type=int, help='Number of data loading workers')\n",
        "    parser.add_argument('--rdm_seed', default=1, type=int, help='Random seed')\n",
        "    parser.add_argument('--device', default='cuda', type=str,\n",
        "                        help='Name of device to use for tensor computations (cuda/cpu)')\n",
        "    parser.add_argument('--display_step', default=50, type=int,\n",
        "                        help='Interval in batches between display of training metrics')\n",
        "    parser.add_argument('--preload', dest='preload', action='store_true',\n",
        "                        help='If specified, the whole dataset is loaded to RAM at initialization')\n",
        "    parser.set_defaults(preload=False)\n",
        "\n",
        "    # Training parameters\n",
        "    parser.add_argument('--epochs', default=3, type=int, help='Number of epochs per fold')\n",
        "    parser.add_argument('--batch_size', default=16, type=int, help='Batch size')\n",
        "    parser.add_argument('--lr', default=0.001, type=float, help='Learning rate')\n",
        "    parser.add_argument('--gamma', default=1, type=float, help='Gamma parameter of the focal loss')\n",
        "    parser.add_argument('--npixel', default=5, type=int, help='Number of pixels to sample from the input images')\n",
        "\n",
        "    # Architecture Hyperparameters\n",
        "    ## PSE\n",
        "    parser.add_argument('--input_dim', default=10, type=int, help='Number of channels of input images')\n",
        "    parser.add_argument('--mlp1', default='[10,32,64]', type=str, help='Number of neurons in the layers of MLP1')\n",
        "    parser.add_argument('--pooling', default='mean_std', type=str, help='Pixel-embeddings pooling strategy')\n",
        "    parser.add_argument('--mlp2', default='[128,128]', type=str, help='Number of neurons in the layers of MLP2')\n",
        "    parser.add_argument('--geomfeat', default=1, type=int,\n",
        "                        help='If 1 the precomputed geometrical features (f) are used in the PSE.')\n",
        "\n",
        "    ## TAE\n",
        "    parser.add_argument('--n_head', default=4, type=int, help='Number of attention heads')\n",
        "    parser.add_argument('--d_k', default=32, type=int, help='Dimension of the key and query vectors')\n",
        "    parser.add_argument('--mlp3', default='[512,128,128]', type=str, help='Number of neurons in the layers of MLP3')\n",
        "    parser.add_argument('--T', default=1000, type=int, help='Maximum period for the positional encoding')\n",
        "    parser.add_argument('--positions', default='bespoke', type=str,\n",
        "                        help='Positions to use for the positional encoding (bespoke / order)')\n",
        "    parser.add_argument('--lms', default=None, type=int,\n",
        "                        help='Maximum sequence length for positional encoding (only necessary if positions == order)')\n",
        "    parser.add_argument('--dropout', default=0.2, type=float, help='Dropout probability')\n",
        "\n",
        "    ## Classifier\n",
        "    parser.add_argument('--num_classes', default=19, type=int, help='Number of classes')\n",
        "    parser.add_argument('--mlp4', default='[128, 64, 32, 19]', type=str, help='Number of neurons in the layers of MLP4')\n",
        "\n",
        "    args= parser.parse_args(args=[])\n",
        "    args= vars(args)\n",
        "    for k, v in args.items():\n",
        "            if 'mlp' in k:\n",
        "                v = v.replace('[', '')\n",
        "                v = v.replace(']', '')\n",
        "                args[k] = list(map(int, v.split(',')))\n",
        "\n",
        "    pprint.pprint(args)\n",
        "    main(args)\n",
        "\n",
        "\n",
        "    #add processing time\n",
        "    print('total elapsed time is --->', datetime.now() -start)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
